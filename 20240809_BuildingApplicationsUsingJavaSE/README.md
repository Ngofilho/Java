`pom` file contains Maven configurations  

The `src` folder contain the `main` folder, which contains all the production and resource folders, and the `src` folder also contains the `test` folder contain any test of the project.     

#### Maven  
- `mvn clean` - Clean all previous compilation code, and remove the target folder.  
- `mvn clean verify` - After cleanning the previous compilation, verifies the application will start from scratch.  

https://app.pluralsight.com/profile/data/author/sander-mak/all-content


[Documentação Java](https://docs.oracle.com/en/java/javase/17/docs/api/)


<details><summary>

### Course Transcript

</summary>


Course Overview
Course Overview
Hi, everyone!. My name is Sander Mak, and welcome to my course, Building an Application Using Java SE. As a Java champion and author of the O'Reilly book, Java 9 Modularity, I've been deeply involved in the Java platform for well over a decade and would love to share some of the things I've learned with you. To really master Java and start building your own Java applications, you need to go beyond learning the language. This course will show you all the tools, libraries, and practices you need to start building real‑world Java applications. By building a real application together, you will have enough knowledge to start building your own Java applications. We'll spend most of our time in the IDE during this course, doing the actual building. Throughout this course, you'll learn about the following aspects of Java application development. Building Java projects using Maven. Using Java language features with Java 17 and beyond. Testing code using JUnit. Calling a web API using Java's HttpClient. Storing data in a relational database using JDBC. And creating a REST API using JAX‑RS. All of these topics will come together in a Java application that we'll build together from scratch. This course assumes you're already comfortable writing Java codes, but maybe you haven't done so yet as part of a larger application. After finishing this course, you'll be able to understand and contribute to large Java application codebases. Of course, you won't be an expert in all the technologies we use in this course, so you can also continue learning in specific areas. I hope you'll join me on this journey to start mastering Java with the Building an Application Using Java SE course here at Pluralsight.

Setting up a Java Application
Introduction
Hey everyone, and welcome to this course, Building an Application Using Java SE. My name is Sander Mak, and I'm a Java champion with about 15 years of experience on the Java platform. In this course, we're going to build a Java application together from scratch. You'll see a lot of Java tools, libraries, and practices that you will also encounter on typical work projects. But first, let's talk a little bit about you. This course is most applicable if you are a beginning or early intermediate Java developer, which means that I will assume that you know the fundamentals of the Java language, including object orientation, knowledge of the collections and streams API, exceptional handling, and other basics of the Java platform. I'm also going to assume that you have worked before with an IDE, but maybe not necessarily with a larger, real‑world Java code base yet. I don't recommend taking this course as your very first course exposing you to Java, especially if you want to follow along with coding yourself. At minimum, ensure you're familiar with the contents of these courses, Java SE 17: The Big Picture for an overview of the platform, Java SE 17 Fundamentals so that you have a firm grasp on the Java language, and the Object‑oriented Programming in Java SE 17 course, so that you also have a firm understanding of object‑oriented Java code. This course has multiple goals. First and foremost, it's designed to make you comfortable with using a nontrivial Java code base, using some of the standard tools and libraries like Maven and JUnit that you will also encounter in real‑world code bases. That means that in this course there will be no small standalone examples, but we're going to build up a complete application together from start to finish. As such, the course will provide a broad coverage of everything related to writing real‑world Java code, allowing you to dive into more details on particular tools, methods, and libraries after finishing this course. You'll most likely see new things, and it's okay if you don't master them all during this course. I will explain just enough around these tools and libraries to start using them, and I will provide lots of pointers to other courses that will go deeper on particular topics. In the end, the goal of this course is to connect all of these concepts together so that you have an overview of what it means to develop real Java applications. It also means that we'll spend most of our time in the IDE, so not a lot of slides in this course. If these goals align with what you want to learn, then this is the course for you. arry on.

Tools Used in This Course
Before we dive in, let's make sure you can follow along by clarifying the tools and versions used in this course. Be aware that this course is not a tutorial on how to install these tools, so we'll assume you have them installed. Nevertheless, I will show you how to verify the correct installation of the tools in the first demo. This course was created using the Java version shown on this slide. You can download and install this Java version from the URL provided here. This means that this course is fully applicable to the Java version shown here. It will not work with earlier versions of Java since we use features only present in the version shown here. However, because of Java's great compatibility across versions, it's expected that these features will also be present and work in later versions of Java, though it is recommended to follow this course with the Java version shown here. There are two additional tools used in this course. First, the IntelliJ IDEA Community Edition, which is a freely available IDE that you can download from the URL shown here. It's not required to use the exact same version as listed here. You can also use newer versions, but in that case, the user interface might be slightly different. Last, we will use Maven as a build tool. Here also the version does not have to match exactly, so I recommend downloading and installing the latest version in the 3.8 range from the URL shown here. There's also an increasingly popular tool in the Java ecosystem called SDKMAN, which you can use as an alternative way to download and install Java and Maven. You can install SDKMan by going to the sdkman.io site and following the instructions there. Then using SDKMan, you can install any Java version or Raven version that you want, and even easily switch between versions if you want to do so. Using SDKMan is not required. You can also just download the tools and install them individually from the URLs I provided, but it can potentially make your life easier if you're going to work with multiple versions of Java or Maven, for example, a version for work and a version for this course.

What Are You Going to Build?
Now, of course, we're going to write Java code in this course, but let's first answer the question what it actually is that we're going to build. Imagine that one morning you come into the office and start chatting with a coworker. You're both sharing how much you enjoy learning new stuff, for example, through Pluralsight courses and through other means as well. You're both asking the question, "How can we actually get others in our company to also learn new and cool technology?" Then suddenly an idea pops up. Why don't we build a course information API for other developers in our company to use? Your colleague is immediately enthusiastic and thinks about all the opportunities of having such an API. You could fill it with your favorite courses, maybe add some notes to it, and then share it with other people in the company, who, also being developers, can use this API to find out what they're going to learn next. So the idea is born. You decide to sit down together and hammer out some requirements. First of all, the application that we're going to build should be able to store interesting courses in a database so that we can retrieve them later. But then in order to expose this information to other developers within the company, we want the system to also have a REST API that other people can call and then get information on these courses that we put into the database. To make it a bit more interesting and tailored to your company, you want to allow the addition of notes to the API to particular courses. And to top it off, your coworker comes with the following idea. Why don't we fill the database with some Pluralsight course information? Hopefully in an automated fashion, of course. So that's it. That is what we're going to build in this course, and we're going to call the project Course Info because it's all about storing and exposing course information. Great! So we know the what. Next question, how are we going to build this? Of course, using Java as a language, but it still leaves many questions unanswered. For example, what are we going to use as a build tool for this code? And how are we going to call the Pluralsight API from Java code? This Pluralsight API will return JSON, so how are we going to parse this and map these two objects? And once we've got that part under control, we need to think about how to expose the REST API and serve it, and by the way, we also need to interact with the database. And since we want to build a real‑world application, we also need to think about testing our code. When you see all these technical challenges and requirements, your first thought might be, let's select the Java framework to handle this for us. And to be fair, that's definitely not a bad thought. There are many Java frameworks, for example, Spring framework and Spring Boot, Jakarta EE, formerly known as Java EE, or Enterprise Java. And there are some new entrants into the Java framework market, like Quarkus and Micronaut, and each of these frameworks can cover a significant part of the challenges that are on the left. However, choosing a framework is a valid choice, but we're not going to do that in this course. Why not? Well, choosing such a framework really shapes your application's architecture and development practices. For this course, I don't want to teach you a framework. I want to teach you Java and how to write an application using Java. And for the application that we're going to build, we don't really need dependency injection and other reflection‑based magic that happens in lots of these frameworks. I want to keep us as close as possible to the core Java knowledge. That being said, learning one or more of these frameworks is definitely recommended, but start with this course to build up an application from scratch before moving towards these larger and more complex frameworks, and I'm pretty sure you'll thank me later for this experience. So the focus of this course will be to stay as close as possible to core Java as we can. However, of course, we will need libraries to supplement our core Java APIs to make all of this possible. So we are going to see quite a few libraries and tools, like Maven for a build tool, Jackson to do JSON handling, JAX‑RS or Jersey to do our REST API, the H2 database, which we are going to access using standard JDBC APIs that are part of Java, and JUnit for testing. Don't worry if you don't know these tools or libraries yet; we'll learn how to use them together in this course. Note, it won't be a deep dive on any of these topics, so there are certainly things left for you to dive deeper into after this course. As a final warning, we're really going to focus on the application development here, so we're not going to dive deep into using Git, for example, for version control and collaboration, or creating a Docker image from our application to distribute it. These are all things that you can figure out separately. All right, so we know what we're going to build, how we are going to build it, but what will the end result look like? Will it be a single application or multiple components? Let's dive into that first. At the end of this course, you will see that we have three components that make up the system. The first will be a command‑line interface tool, and this command‑line interface tool will be responsible for calling out to the Pluralsight API, parsing the JSON response, and storing it into the database. Next to the command‑line interface application and the database components, we will also create a REST API server. Because remember, we want your colleagues to be able to call this API to get course information that was stored in the database. This diagram gives you the complete overview of what we're going to build in this course. That's, of course, still a bit abstract, so what does this look like in action? Our Course Info Server components, which serves the REST API, will be able to respond to a /courses call on localhost, and we'll respond with a JSON representation of all the courses that are stored in the database. As you can see, a course has an ID, a name, a length, a URL, and some optional notes. In principle, you could store any course in the system, as long as you have a link. Then we said the API should also allow for addition of notes, and we will model this using a custom URL in the REST API where you can post notes. Of course, we do want to fill the database with courses and we don't want to do so manually. So our Course Info CLI app will be able to call out to the Pluralsight API, retrieve courses for a given author, and store them in the database. Once finished, it will roughly look like this, where the command‑line application will retrieve courses for a certain author, in this case, my courses, and then store them in the database so that they can later be served by the API. The completed application can be found in the GitHub repository shown here. You can use it if you want to look at the end results, but you don't actually need this repository to follow along with the course. Because like I said, we're going to build this whole system from scratch together. In the module you're currently watching, we'll start with building the CLI components. And then in the next module, we'll extend this component to call out to the Pluralsight API. And in the subsequent modules, we'll gradually build the application out to store the data in the database, exposing it over a REST API, and finally, make it ready for production in the last module.

Setting up a Maven-based Java Project
As a first step, we're going to set up a new Java project using Maven as a build tool. And we'll be doing this inside of IntelliJ, the IDE. You may not yet be familiar with Maven as a build tool and wondering why do we actually need a build tool if we already have an IDE that can build Java code for us? The idea is that by using a build tool like Maven, we are separating the responsibility of building our application, so actually compiling, and creating the reliable application from the actual development that happens inside of the IDE. This way we're able to build our application also outside of the environment of a developer machine. For example, by running the Maven build as part of a continuous integration environment. Using Maven will also force you to adopt a uniform layout of your source codes, organizing production Java codes, test codes, and other resources in a way that is universally recognized by Java tools. You may also call this convention over configuration. Once we have set up the application in IntelliJ, I will show what this uniform layout looks like. Based on the standardized layouts, Maven is able to out‑of‑the‑box compile and run your tests automatically. It will manage also the class path of the compiler so that any dependencies that we might want to use in our application are also presented to the Java compiler. And in general, Maven gives you a reproducible build process across different environments. Finally, Maven is also able to actually download dependencies for you and manage these dependencies as part of your Java project. But let's not get ahead of ourselves, and first set up the application using Maven focusing on the first two points. If you want to dive deeper into Maven beyond what we'll touch upon in this course, then I can highly recommend checking out the Maven Fundamentals course here at Pluralsight. Before we open the IDE, let's circle back to the diagram of the system that we're building quickly. In this first demo, we're going to create the outline of the command‑line interface tool so that in the next module, we can extend it with actually calling the Pluralsight API. Now let's get started by setting up a new Java project using Maven in IntelliJ. When you start IntelliJ, you're greeted with this screen. It may look slightly different if you're using a newer version than the version I'm using, but the gist of it should be the same. It shows you an overview of any projects that you may have already worked on, but it also gives you the opportunity to create a new project. And that's what we're going to do by clicking the New Project button. We already know the name of our project, so we call it course‑info, and the Create Git repository option is checked by default. I recommend you leave it on, even though in this course, we're not focusing on using Git and we will not be committing anything. If you already know Git, then it's useful to put the code that we're creating into a repository and commit your intermediate results every now and then. Note how Java as a language is already selected, as is Maven for the build system. Maven is the most popular build tool in the Java ecosystem, which is probably the reason why it's selected by default. Then there's a drop‑down where we need to select a JDK version. As you can see on my machine, it already detected an installation of Java 17 and selected that. If that's not the case for you, then you should open a drop‑down and select Java 17. If it's not already there yet, you can either add it by going to the right directory and using the Add JDK option, or you can even download a JDK using IntelliJ using the Download option. At any rate, the end result should be that you see Java 17 selected in the JDK drop‑down. We're also quickly going into the Advanced Settings. Here we can configure the so‑called GroupId and ArtifactId, which are Maven concepts that will come back later. For now, let's change the GroupId to com.pluralsight, and the ArtifactId is already the same as the name of a project, which is okay for now. Okay, let's hit the Create button and see how IntelliJ sets up the project. First of all, a pom.xml file has been generated, which contains all the Maven build configuration. It is already opened by IntelliJ and shown here. The same GroupId and ArtifactId that we saw in the dialog are also shown in the pom.xml file. And as you can see, a version element has been added because every Maven artifact needs to be versions. There are also two properties defined, making this a Java 17 project. We'll get to those in a second. But I first want to draw your attention to the layout of the project as it has been generated. Looking into the src folder, we see a main and test subfolder. The main folder will contain all of our production codes and resources, whereas the test folder will contain any test code that we're going to write. Again, this layout of the source code is enforced by Maven. And as long as you stick with this, Maven will be able to do a lot of things for you automatically. I also quickly want to show how this .gitignore file was generated because we indicated to IntelliJ that we also wanted to initialize a Git repository for this project. Many of the files that are being excluded in this Git ignore file are IDE‑specific files. And that's a good thing because you should never commit any IDE or machine‑specific files into your source code repository, and we don't need to because we have the pom.xml file that will contain all of the information to build our application using Maven, and IntelliJ is able to derive all of its own configuration for the project from this pom.xml file. Which brings me to the first change that we're going to make to this automatically generated pom.xml file. While setting the source and the target of the Java compiler will work, there's also a new flag on the Java compiler that you can use called release. I won't go into the details on why it's better to use this release flag, but I do want to show you how to configure this. We're going to replace the two properties by a single maven.compiler.release property, which ultimately will be propagated to the Java compiler invocation as a ‑‑release flag, and we will leave the value at 17 because in the end we're creating a Java 17 application. Now, there's a few interesting things that you should know. As I said, IntelliJ is able to derive all of its settings from the pom.xml file, and it has done so already. But what if you change something in the pom.xml file? This change by default will not be picked up automatically by IntelliJ. If you change something in the pom.xml configuration, you can go to the View menu, go into Tool Windows, and open the Maven tool window. There's a Refresh button that he could use to sync IntelliJ up again with the current pom.xml state after the changes that we made. In our case, because we're going to make many changes to the POM file during this course, I will go into the auto reload settings of Maven in IntelliJ and change the setting from only reloading the project after external changes to reloading on any changes, which means that any time we change something in the pom.xml file, it will be synced to the IntelliJ configuration automatically for our project. All right, so we should be good, right? Well, not quite. Let me show you what just happens. I'm going to open the IntelliJ Modules settings for this project, which should be in sync with what we just did in the pom.xml file. But if we look at this Settings dialogue, you can see that the language level for this project is set to Java 5. Well, that's pretty old, right? And that's definitely not what we want. We want to have a Java 17 projects, as we just configured using the new release flag. It turns out that in the default configuration of Maven, it uses a quite false Maven compiler plugin, which in turn will invoke the Java compiler. And this Maven compiler plugin does not yet understand the maven.compiler.release flag that we just added. We can fix this by configuring a build section in our pom.xml, and within this build section were going to define a plugins section, and then configuring the Maven compiler plugin to be of a newer version, in this case, 3.10.1. This version or any later version of the Maven compiler plugin will understand how to handle the maven.compiler.release flag that we configure. Since we configured IntelliJ to automatically sync Maven changes back to the IntelliJ configuration, we don't have to do anything now, and we can open the module settings again. And as you can see, now the language level 17 is selected again. As a side effect, we're also using a newer version of the Maven compiler plugin, which works much better with Java 17 than the default older version that Maven would otherwise select. If you don't want to type this build section into your pom.xml file by hand, you can also copy it from the GitHub repository that contains the final version of the application. So we took the first hurdles in setting up the project. Now it's time to actually write some Java code and see how we can build it using Maven.

Building and Running the First Class
We'll create a new class by right‑clicking on the Java folder in the main directory, which means that the class that we're creating is going to be production codes rather than test codes. And then we can give it a name, but rather than just giving it a plain name, we are also going to introduce a package structure here for our classes because in the end, any large‑scale Java application will put classes into packages for organization. In this case, we're going to put the class into the com.pluralsight.courseinfo.cli package. Let's break this down a little bit. The com.pluralsight parts corresponds with the group ID that we see in the Maven POM. Typically, the group ID, more or less uniquely identifies your company as owning this code. But since we're doing this as part of a Pluralsight course, I've chosen com.pluralsight as a group ID. Then the next level is course info, which corresponds to our artifact ID, which in this case is the name of our project. Then the final package level. .cli, it may be strictly not necessary yet; however, we've already seen that we're going to create multiple components within our application, so it makes sense to already split out the CLI components into its own package. Now that we've indicated the package where the class should live, we can actually provide the name of the class. Our class is going to retrieve courses from the Pluralsight API, so let's call it CourseRetriever. Because we initialized a Git repository, IntelliJ asks us whether we want to add this file to Git. I'm going to click Don't ask again because we're not going to use Git, like I said in this course, and I'm going to cancel the dialog so it won't be added, but it's up to you whether you actually want to use Git and add the file and commit it later. That's also fine. Now we have a simple empty class called CourseRetriever in the write package, as you can see by the package statement at the top. Let's add a public static void main method because in the end, we want this class to be run from the command line, and this is the way to make that happen in Java. We'll just put a simple system of println in there so that we can see it working. Just to check that everything works correctly, let's right‑click on the CourseRetriever class and select to run it. IntelliJ compiles the class and runs it. And there we go, we have the output that we expected. What's also interesting to see is that a new target folder has been generated containing the compiled class. Again, this target folder is something that is dictated by Maven. And as you can see, IntelliJ used this convention of Maven to also emit its compiled class into this target folder. Now, let's take this a step further and see if we cannot just compile the application using IntelliJ as we just did, but rather compile it using Maven directly from the command line. To do this, I'm going to IntelliJ's View menu again to the two Windows, and in this case, I'm going to open the Terminal view. Let's first do a check whether Java 17 and Maven have been installed correctly. Just run java ‑‑version, and you should see output similar to this. The actual name and exact version of the JDK might be different, but you should at least see that the version of the JDK starts with 17. After installing Maven, you can also use Maven from the command line using the mvn command. So let's run mvn ‑‑version, and you should see outputs similar to this. Again, the exact version of Maven doesn't have to match exactly, as long as it's a release in the 3.8 range. The first real command we're going to issue with Maven is mvn clean. The commands that you provide to Maven are also called targets, and the clean targets is meant to clean out any compilation results. So if we run this, you will see that the target directory containing the compiled class has actually disappeared. By the way, you may see much more output from Maven than I show here. Because if you run Maven for the first time, it will also download some plugins and other dependencies that it needs to function. You can also provide multiple targets to Maven. So let's run mvn again and provide clean, but also verify as a target. This is a very typical Maven invocation where you first ensure that the old compilation results are cleaned up, and then by adding the verify targets, you make sure that the application is built from scratch again, running any tests and doing any other work that needs to be done as part of the build as well. As I said earlier, this course is not meant as a deep dive into Maven, so if you want to understand this further, I highly recommend checking out the Maven Fundamentals course on Pluralsight. Now let's run this mvn clean verify invocation. After the builds, we see the target folder appearing again, but in this case, it wasn't IntelliJ who compiled the class, but it was Maven using the Maven compiler plugin that we configured. You can see that Maven emits even a bit more into the target folder, but let's not dive into that too much now. The interesting thing to note here is that by using the verify targets, the application is also packaged into a .jar file which is also put into the target folder. We see that the build succeeded, which means that compilation was successful. And that's great. But if we scroll back a little bit in the output of Maven, we also see there's a warning about a file encoding not being set, so it's falling back to the platform defaults. Now, this is currently not breaking anything, but as indicated by the warning message, it does make our build machine or platform dependent. And one of the goals of using Maven is to create a reproducible build that works the same across all machines. So we can address this warning by actually configuring a file encoding in our pom.xml file. So let's move back to pom.xml and add a new property called project.build.sourceEncoding and set it to UTF‑8, which is a much saner default for Java projects. Now, if we run the Maven build again using mvn clean verify, you will see that there are no warnings anymore. So we're all good. We have a simple Java class, which we can build and run using IntelliJ, but we can also build it using Maven. And any changes that we make to the pom.xml file will be automatically picked up by IntelliJ, which means that we're finally ready to get on with coding. As the last step in this demo, we're going to add some argument parsing to our main methods. Because in the end, what we want to do is to provide an author ID on the command line as an argument, which we then use to call the right Pluralsight API URL. First, we'll add an if check, looking at the length of the arguments provided. And if it's 0, we want to give a nice message telling the user to actually provide a course author ID. And after printing the message, we can return, effectively terminating the program because we cannot do anything without having an author name. Now, assuming we come out of if, we know there's an argument, and we can pass that to a new retrieveCourses method. Note how I just type retrieveCourses and then use ALT+Enter to get a suggested fix from IntelliJ, and then we can just click Create method retrieveCourses in CourseRetriever, which is a nice time saver. I want to rename the parameter arg to authorId. And since we're not going to call out to the Pluralsight API just yet, we'll just print out a nice message that we're going to retrieve courses for this particular author. We're going to run this class again, see CourseRetriever status, and also our methods of please provide an author name as first as argument because, well, we started the application without providing any arguments. So how can we actually do this because we're not running the application from the command line where we could easily add this command‑line arguments? To make this work, we need to go into the run configuration for the class that we're running. And we can do this by opening IntelliJ's run menu and then selecting Edit Configurations, which will bring up a dialog containing all run configurations, which at the moment is just a single one for our CourseRetreiver class. We can now use the program arguments, text box to provide any arguments to the application. We'll add sander‑mak, which is my name and author ID at Pluralsight, and from now on, this will be provided as an argument when running the CourseRetriever class. Let's verify that by running CourseRetriever again. And there we have it. It now says retrieving courses for author Sander Mak. So, that's good. Let's wrap up the setup by adding one more thing. I want to make sure that we have some top‑level exception handling in place for the application that we're going to write, and we will do this by introducing a try catch around the RetrieveCourses call, but it will ensure that we can catch any random exception, and we could also propagate any checked exceptions if we want to, and we can all handle them uniformly in this top‑level exception handler. For now, we'll just print that an unexpected error happened, and we'll print the stack trace of the exception, and we'll tidy this up a bit more in the next demo. But the point here is that I want to have a single catch‑all exception handler that we can rely on if an exception is not handled elsewhere. Of course, there might still be good reasons to somewhere else in the code, down in RetrieveCourses and whatever that might do to also have alternative catch statements and handle a certain exception in a more specific way, but for any uncalled exceptions in our downstream code, we now have a single place where we can handle them. And that's it. We took quite a few steps to set up this project correctly as a Maven project, but we're now ready to extend it further and reap the benefits of using Maven.

Introducing Your First Dependency
We created the first skeleton class, which currently prints the system out. That's not great. Most Java applications use a logging library. Such a library offers a nicer API to create parameterized log messages, and it allows you to distinguish between different levels of messages, for example, debug level, info, or error level messages, and usually it also provides a way to configure logging without changing the code. For example, to change the current logging level for a certain class or package. Last, but certainly not least, these libraries give the opportunity to log to different backends rather than just printing to System.out. For example, logging to a file or to a centralized logging system. All in all, enough reason to integrate a logging library as a first step into our application. Unfortunately, Maven makes this easy. Besides being a build tool that you can run locally, Maven also offers a central repository of Java libraries. There's no need anymore to go into a project's website, download the .jar files, add them to your source code repository, check them in. Locating and downloading dependencies can all be handled using Maven. And by now, it will probably not surprise you that we're going to add these dependencies in our pom.xml file. By adding a dependency, Maven will be able to locate the right artifacts in the Maven central repository, download it to your machine, and make sure that the Java compiler references this library. This downloading of dependencies may sound a bit heavyweight, but rest assured there's also a local cache of downloaded libraries so that in principle, it will only be downloaded once. In order to add a dependency, you need to know its groupId, artifactId, and the particular version that you want to use. In the upcoming demo, we're going to add the SLF4J library, which we are going to use for logging in our application. We'll get back to this particular dependency declaration later on in the demo, but before opening the IDE again, let's talk a little bit about SLF4J. It stands for simple logging facade for Java. So why do we actually need a logging facade, and what does it mean? Logging and logging libraries in Java are a bit of a mess with many libraries to choose from, all with their own strengths and weaknesses. There's Log4j, Logback, and even the JDK itself also has a logging API. Instead of choosing one of these libraries, we can use SLF4J, which offers an API that abstracts over the underlying implementations. Then you can use and later easily swap out an implementation if you want to. By using SLF4J, your application only needs to know about the SLF4J API and not about the particular implementations that power the logging. In this demo, we're only interested in using SLF4J as the API to write log statements for our first Java class. Now, our goal for this demo is to add SLF4J as a library to our project and start using it for logging. Since all of our build configuration is handled through Maven, we're also going to add the dependency here. We can do so by introducing a new dependency section in the pom.xml file and adding a first dependency elements. Now let's assume that you didn't see the groupId artifactId version for SLF4J in the previous slides. What are you going to put here for the coordinates? You don't really know, right? So the question is, how do we find out? Let's remove this half‑baked dependency declaration for now and try to see if we can find the Maven coordinates for our dependency otherwise. Fortunately, this Maven central repository hosting Java libraries also offers a search functionality. You can go to search.maven.org to start searching the Maven central repository. We'll put in SLF4J as a search query, and the top results already points us in the right direction. Let's click on the org.slf4j group ID. This provides an overview of all artifacts hosted under this group ID, with the latest version published to Maven Central in the third column. We are interested in the slf4j‑api artifacts because that contains the logging API, which forms a facade over other implementations, rather than directly clicking through to the 2.0.0‑alpha7 release, which, by the way, at the point that you are searching Maven Central might already be a newer release. I'm going to click on the number that's after the latest release, bringing us to the complete version overview of this particular artifact. I don't really want to use an alpha release for a project, so I'm going to click through on the latest version that is not an alpha release, which in this case is 1.7.36. You can pick a newer version if available, but I would advise to stick with the 1.x line for this project, as 2.x might introduce API changes as a major new version. Artifacts published to Maven Central are encouraged to follow semantic versioning. While you could pick a newer version, you can also pick the exact version 1.7.36 because nothing ever disappears from Maven Central once it has been published. Why? Well, somewhere, some build depends on this particular version, and builds always need to be reproducible. So that's why artifacts can only be added to Maven Central, but never removed. Once we click through to this particular version, we see more details, and especially on the right‑hand side, we see a dependency declaration for Apache Maven that we can use in our pom.xml file. There's also snippets that you can use in other build tools, like Gradle and SBT, which is interesting because while they are other build tools, they do use Maven Central as their repository to retrieve artifacts. And that's actually a great thing because it makes Maven Central the authoritative source for virtually any Java library in existence. So to use this dependency, we're going to copy the coordinates. And by the way, from now on, we'll assume that we know the coordinates for new dependencies that we're going to add. But if you have a new library that you want to use, go to search.maven.org in order to find the exact coordinates to use in the pom.xml file. One last warning about adding external dependencies to your project before we actually do so. Adding dependencies is a very powerful way to get new functionality and to make yourself more productive. But it also comes with downsides because it means you now have code in your application that you did not write yourself. But there could still, for example, be security vulnerabilities in this code. If you add a dependency to your Java projects, remember you are on the hook to keep these dependencies up to date, to make sure that you're not running an old version containing security vulnerabilities. All right, that's enough warnings and caveats. Let's take the dependency and add it to our pom.xml, we can paste it into the dependencies section. And since we configured IntelliJ to automatically sync with any changes in our pom.xml file, we can now click on External Libraries and see that IntelliJ has also recognized this dependency, meaning that we now can start using it in our Java code. So let's move to the CourseRetriever class and initialize a logger in a private static final fields. Note how the auto‑complete in IntelliJ offers us multiple types, but we are interested in the org.slf4j logger that we just introduced as a dependency. Then we use a static method, a LoggeFactory, which also comes from SLF4J, to initialize a logger to be tied to this class. And with that, we've set up a logger that we can use in our code. Now, we can start rewriting the System.out.println statements to actual logging invocations. Let's rewrite the first System.out into an info‑level log message, and rather than saying that the application has started, let's be a bit more truthful and say that the application is starting. We'll turn our second message into a warning because something needs to be fixed here. If you want to, you can explore the API yourself a bit further to see what other logging levels are available in SLF4J. In the catch block of our top‑level exception handling, we are going to turn the System.out.println into a error log. And the interesting thing here is that SLF4J provides an overload for the error method that takes a message which is the first string, but also a throwable, which is the exception. By using these overloads, we ensure that the exception is logged appropriately, which means it also includes a stack trace. Therefore, we don't need to eat a printStackTrace anymore. Finally, we turn the last System.out.println into a LOG.info message, but again, we can make better use of the SLF4J API by using its so‑called placeholder syntax. Rather than concatenating the string ourselves, we can introduce two curly braces as the location for the authorId to be inserted. Let me also put some quotes around it because it's easy to do now, as we don't have to do a concatenation ourselves. AuthorId is now provided as a second argument to the LOG.info call. And in fact, you can pass any number of arguments after the message, and you can have multiple placeholders in the string that will then be replaced with the multiple arguments that he provides, which makes for a very nice way of constructing log messages. One other reason why the API was designed this way was for optimization purposes. If SLF4J determines that the current log level that you're logging at is disabled, it will not even create the final log message, saving some CPU cycles. Now that we've updated our class to use a logging library, let's try to run it and see what it looks like. Hmm, that is not looking too good. It says something about failing to load a class and defaulting to a no ‑operation longer implementation. Now to understand this problem, let's go back to the diagram that we saw previously on how SLF4J works. As we saw, SLF4J is an API that tries to unify multiple implementations. But crucially, it itself is not a logging implementation. So what we see here is that we have the API available, but there's no implementation for it to use. We could solve this by using log4j or logback or one of the other listed implementations, but for this project, we're going to use a lightweight implementation that is offered by SLF4J itself called SLF4J Simple Logging. And, of course, for that to work, we need to add it as another dependency to our pom.xml file. But fortunately by now we know the drill. So let's head back to the pom.xml, copy our SLF4J API dependency declaration, and change it to also include the SLF4J simple artifacts. As you can see, IntelliJ also offers autocompletion here, so it's also aware of the contents of Maven Central, which is pretty cool. So now we have two dependencies for our application, one for the SLF4J API, and one for the SLF4J Simple Artifacts. We've declared these dependencies in the same way. However, the way we use them is subtly different. For the SLF4J API dependency, we're actually coding against this API and compiling against it, whereas for the SLF4J Simple Artifacts, we're not going to use any types from this artifact or compile against it, but we just want to have it available on our class path when running the application, so that SLF4J selects this implementation as its logging back end. As it stands in a pom.xml file, this will work fine, but we can improve things a bit more by being more specific about the scope of our dependency. By default, dependencies declared and made in this way have the compile scope, which means that the artifact will be present on the class path when compiling and when running the application. By changing the scope of the dependency on the SLF4J Simple Artifacts to runtime, we ensure that this .jar file will be present on the class path when running the application, but not when compiling the application. Why is that a good thing? Because it prevents us from writing any codes that references types in this SLF4J Simple Artifacts and prevents us from taking a compile time dependency on this specific logging implementation. If we only have a compile time dependency against the SLF4J API, then we can later switch out the implementation easily without changing any code. Now it's time to run our application again. And as you can see, the log messages now appear in the console. Every log line is formatted in a similar way. Between brackets it shows the name of the current threads, then it shows the level of the current log message, then the class where the log message originated, and then after the dash, the actual log message. There's one last thing that we can improve here. We repeated the version of the two SLF4J artifacts, even though they are closely linked together. If we want to upgrade to a newer version of SLF4J, we would have to change it in two places, which is not quite optimal. We can fix this by introducing a new custom property in our pom.xml file. Let's call it slf4j.version and put in the 1.7.36 as a value. Now, we can replace the actual versions to reference the property using a $ with curly braces. And by replacing both versions with the property reference, we now have a central location to manage our SLF4J version. Let's do a quick check on external libraries just to see that IntelliJ also picked up on these changes. And indeed, we see that we still have both artifacts with version 1.7.36. That brings us to the end of this demo where we introduced the first dependencies into our projects using Maven.

Summary
In this first module, we've created the foundation for our course info Java projects. We created a new Java project using Maven as a build tool from scratch. And although we use IntelliJ to code and run the application, in the end, Maven governs the whole build cycle, which gives us a reproducible build that will work on all environments. Finally, we saw how we can add dependencies to our project using dependency declarations in our pom.xml file. Maven then manages the downloading of these artifacts and ensures they are presented to the Java compiler on the class path. Because IntelliJ understands everything that we put into the pom.xml file, it too sees the dependencies and allows us to use them with autocompletion and everything that we would want inside of the IDE. Now that we have the scaffolding in place, in the next module, we're going to tackle our first challenge, which is calling a Pluralsight API to get courses for an author.

Calling an External Web API
Overview
So in the previous module, we spent quite some time setting up the project using Maven, IntelliJ, understanding how to introduce new dependencies, but in the end, we currently only have a CLI tool that does some logging, which is hardly impressive. So let's fix that in this module. We're going to extend the CLI tool such that it can make HTTP API calls to a pluralsight.com API that will return course information for a given author. To implement this, we're going to use the HttpClient API, which is part of Java since Java 11. Before Java 11, people typically used external libraries to do HTTP calls in Java. But this relatively new HTTP clients API in Java is actually quite powerful, so we don't have to reach for an external HttpClient library. Initially, we'll just treat the return JSON from this API as a string, but ultimately, we want to work with objects in Java code. So we will create an object, modeling the data from the response we're interested in, and we're going to do that using Java Records, which were introduced in Java 17 and are quite well‑suited to the task of creating data classes. The next challenge that we're going to have to address is how we can take a JSON string and instantiate a record with the actual data so that we will have a Java object instance representing the data coming back from the API. In this case, we're not as lucky as with the HttpClient API because there's no real API in the Java standard library to do this. Therefore, we will be using an external library called Jackson, which is a quite popular library for mapping JSON to objects in Java, and vice versa. Finally, since we'll be writing some nontrivial codes, we are also going to introduce the first unit tests in the application. We're going to create and run these tests using JUnits, which is the most popular unit testing framework in the Java ecosystem. Now it's clear what our objectives are for this module, so let's head back to the IDE.

Using Java's HttpClient
In this first demo, we're going to use the Java HttpClient API to make a call to a Pluralsight API. You'll see the HttpClient API in action, but keep in mind this is only one scenario, and there's much more to using the HttpClient API that we won't cover in this course. If you're not satisfied with this and want to dive deeper into the HttpClient API, please check out my Java Fundamentals HttpClient course on Pluralsight. Now, let's head to IntelliJ and start using Java's HttpClient. We are back in our CourseRetriever class where we left off in the previous module. Now, we could start writing all the HttpClient interaction codes right here in this CourseRetriever class, but we know that at some point, we also want to store the classes in a database, and it seems like we're mixing a lot of concerns in this class if we do that, and it might get cluttered. So to keep things clean and to separate concerns, I'm going to introduce a new class, which we will call CourseRetrievalService. A quick way to introduce this class is by just writing the code, even though we have not created the class yet. Therefore, I'm just going to introduce a local variable CourseRetrievalService of type courseRetrievalService, even though this class doesn't exist yet, and I'm going to call the constructor for it, which also doesn't exist yet because the class is not there. Of course, IntelliJ knows this and marks everything red, but then we can use the old enter shortcuts to open some quick fixes. And the first suggested fix is to create a class called CourseRetrievalService, which is exactly what we want. So let's select the first option, and then IntelliJ prompts us for the destination package of this new class, defaulting to the package of the current class. Since at a later point we're also going to introduce a service to store courses, let's create a new package called service to put these classes in. And this automatically gives us a new class in a new package, which is also imported automatically in the CourseRetriever class, as we will see later. We want to implement a single public method, getCoursesFor, passing in the authorId, and the question is, what will be the return type of this function? For now, let's just assume that we are going to return the raw JSON string as we receive it from the API. And since we're not calling the API yet, let's return an empty string for now. With this simple domain implementation, we can already code up the usage of this CourseRetrievalService API in the CourseRetriever class, which means that we're going to call getCoursesFor with the authorId that we have, and we're just going to log the results. But now it's time for the real work. How are we going to call this HTTP API, and what does it even look like? Let's go to the browser and see what kind of response the API will return. We can make a simple HTTP GET request to this URL, which, as you can see, returns a lot of JSON, in this case, an array of JSON objects where each object contains the metadata for one of my Pluralsight courses. If you try this yourself, it might look different in your browser, maybe more like this raw response. The reason why it looks so nicely formatted here is because I'm using Chrome with a custom extension called JSON Formatter, which renders any JSON return to the browser in this nice way. And since we're in the browser anyway, let's talk about another important topic, documentation. We don't yet know that much about the HttpClient API, but fortunately, the Java Standard Library is very well documented in a format called javadoc. Javadoc is written as part of Java source code, but it can also be published on the web, and we can find the javadoc for the Java 17 Standard Library by Googling for javadoc 17 and following the overview link to the javadoc hosted by Oracle. This overview page lists all the top‑level modules that are part of the Java platform. And interestingly, we here see the java.net.http module which defines the HttpClient and WebSocket APIs. Another handy feature of javadoc is that it's searchable. So if we go to the search bar and type in HttpClient, we can see a hit on the java.net.http.HttpClient class and go there directly. But as you can see, there's example codes and explanations of how the HttpClient API works, so I want to encourage you to have a look at this yourself just to get an initial feeling for this API before moving on with the rest of the demo. After having looked at the javadoc for the HttpClient API, we can now go back to the CourseRetrievalService and start using it. Let's first define a string constants containing the location of the API that we're going to call. Note that I've replaced the actual authorId with a %s, which is a placeholder that we can use to format a string into an actual URL using standard Java string formatting functionality. Next, we need an HttpClient instance. We're going to also declare this as a private static final fields, because a single HttpClient instance is thread safe and can be shared among many calls, and it is more efficient to only instantiate the HttpClient once. We're going to use the new HttpClient static factory method that gives us an HttpClient with all default settings, and these defaults work fairly well in practice. Although we will tweak this HttpClient instance towards the end of this demo a bit. With this setup in place, we can start using the HttpClient inside of our get CoursesFor implementation. And as you may have spotted in the examples in the javadoc, there's a send method on the HttpClient that we can use to send a request. Now, we haven't actually defined the HTTP request yet, but we'll get to that. There's also a second argument we need to provide to the send method, which is a so‑called BodyHandler. A BodyHandler is responsible for taking the raw response bytes of the server and turning it into a Java object. As discussed earlier, in this first step, we're just interested in getting the JSON as a string into our Java code. So we can use an existing BodyHandler called ofString, which will take the response bytes of the HTTP server and turns it into a Java string. We still need to define the HTTP request. And again, IntelliJ can help us here. Let's use Alt+Enter again to see the suggested quick fixes and use the first one, Create local variable 'request.' This introduces the request variable using the HttpRequest type. Most of the objects in the HttpClient API follow the builder pattern, and the HttpRequest is no exception. So we can invoke newBuilder, passing in the URI that we want to call. We instantiate a URI using URI.create and passing the string ps_uri, but remember, there was a placeholder in there, the %s where the authorId needs to be inserted. To achieve that, we use the formatted function on the string and pass in the parameter that we want to place at the placeholder. As an aside, if you don't want to type the URL from the screen, you can, of course, copy paste it from the GitHub repository containing the full application. If you look at the CourseRetrievalService implementation there, you will also see a fallback URL. It is not expected, but it might be that the URL for the Pluralsight API changes at some point, or maybe the return payload changes. And in both cases, our application could fail. That's why you alternatively can use this fallback URL, giving back a predetermined JSON response containing a snapshot of the course information of all my courses at the time of the creation of this course. If you are forced to use this fallback URL, it does mean that you cannot change the author, since you're not calling to a real API and are getting back a static response. All right, with that out of the way, we're still in the construction phase for building an HTTP request. And as the next step in our chain builder invocation, I'm going to indicate that this is an HTTP GET request. This is not strictly necessary, since the builder assumes by default that any request which doesn't have a specification of what kind of HTTP request it is will be a GET request, but I think it's better to be explicit in your code and make sure that people understand that this will be a GET request. Now we can call builds, and we get back an HTTP request object, which is an immutable object that we already passed to the send method, so it knows what to do. But as you can see, the code still does not compile. And if we hover over send, we get some additional information. IntelliJ tells us that the send method can throw two checked exceptions, IOException and interruptedException, so we'll need to handle those. Additionally, you also see the javadoc belonging to the send method. So we've now seen two ways to explore javadoc, either in the browser on the Oracle websites, or here directly in the IDE. Let's introduce a try and catch around client sends, and we're also moving the return statements inside of the try. And now we need to deal with both IOException and interruptedException. We could introduce two catch blocks for these specific exceptions, but there's really not that much that we're going to do differently here for these exceptions. So instead I'm going to make use of Java's ability to catch multiple exceptions in a single block, using this syntax, and then inside the catch, we're going to throw a RuntimeException that wraps the checked exception and provides a nice message of what actually went wrong, in this case, that we could not call the Pluralsight API. If there's nothing you can really do to recover from a checked exception, then throwing a RuntimeException that wraps it is a pretty common pattern in Java applications. Remember, we also introduced a top‑level try catch in our application, which in this case would catch the RuntimeException and log it for us. Now the code compiles, but it still doesn't do what we want it to do because we're returning an empty string, and instead we want to return the JSON that we got back from the API as a string. To make that happen, we're going to assign the results of the send method to a variable. And I'm going to use IntelliJ's introduce variable refactoring for that. Take a look at the associated shortcuts. In my case, Alt+Command+V because this is a refactoring that's often very handy to use. So now we've got a variable of HTTP response of string, and the string is there because of the BodyHandler that we used. And with that, we can use the response to return the body which is of type string and is exactly what we need here. Okay, this should do the trick for calling this API. So let's try it out. We'll switch back to the CourseRetriever class where the run configuration is still providing a first program argument of th dash mark. So if we're going to run this application, we see the JSON that was returned from the Pluralsight API in the final log line. Now, this is a pretty big step for the application, right? We're finally calling a real API and getting back JSON.

Improving the HttpClient Usage
Of course, there are still a few more steps to take, but let's wrap up this demo by going back to the CourseRetrievalService class and making the HttpClient interactions a bit more robust. The first thing I want to show is that you can also use a builder API for configuring in HttpClients, rather than using the default new HttpClients satisfactory method. We can call new builder on HttpClient, and then we can add configuration options to this HttpClients before instantiating it using builds. In this case, I'm going to configure the HttpClient to always follow Http redirects if the server returns those. That way, if in the future the location of this API changes and redirects have been set up correctly on the server side, the Java HttpClients will transparently call this new URL that is returned as a redirect URL from the server. Now, we still need to call build to get back an HttpClient instance, and now we have a custom configured HttpClient rather than a default HttpClients. There's also one other change I want to show. Currently we immediately give back the response body. But as you may know, an HTTP server can also respond with an error code. And in those cases, it may not make sense to return the body, or there might not even be a body at all in the response. So let's deal with this by inspecting the status codes of the response object that we have. And we're going to implement this using a relatively new Java feature that is a switch expression. This is a new form of switch in Java where the switch actually returns a value, and which value that is depends on which of the cases of the switch matches. So let's see what it looks like. We can switch on the response.statusCode, and this will give an integer representing the HttpStatus code. So in the case of a 200 status code, which means OK, we're going to do as before and return the response.body. Note how we are returning the whole switch expression. And then inside of this case 200, we're indicating that the return value if case 200 matches should be response.body. And because of the error syntax after the case, we don't need to add any return statement inside of the switch, as this switch will take the expression on the right‑hand side of the arrow as its return value should this case match. We could also get back a 404 Not Found from the API, and in that case, we could choose to not blow up the whole application, but just return an empty string. You could also throw an exception here and that would also be a valid approach. But for now, let's handle this one a bit more gracefully. Now, we haven't yet covered all cases, and in a switch expression, all cases must be exhaustive. Of course, we're not going to enumerate all integers that are possible with case, so we're going to introduce a default case that matches if the response status code is not 200 and not 404. And in this default case of the switch, we are clearly getting an unexpected results, so we'll throw a new runtime exception, indicating that the Pluralsight API call fails, while also adding the actual status code of the response for debugging purposes. And with that, we implemented our first step of interacting with the Pluralsight API. Now let's see if we can do better than just treating the JSON that we get back as a string.

Introducing a Java Record
In this demo, we're going to model Pluralsight courses in a nice way in our Java code. We could use regular Java classes for that, but as of Java 17, we have a cool new feature called Java Records, which are explicitly meant to model data in your code. So it's a great fit to model the data for a Pluralsight course in our code, and we're going to use a Java Record to do so. You're most likely not that familiar with records yet. And in this demo, you'll get a first taste of what they look like and how they work. But if you want to dive deeper, there's also the Java SE 17 Advanced Language Features course, which has a complete module dedicated to Java Records. Before we move back to the code, let's look at the JSON again that is returned by the Pluralsight API. In this response, we see multiple courses, and each course has many properties. For our course information system, we're not interested in all of them, so we will model a subset of these properties in our Java code so that in code, we only have to deal with the properties that we're actually interested in. For our system, we're interested in the title, the id, the duration, the contentUrl, and the isTetired flag, which means that we can discard quite a bit from the JSON response. Going back to IntelliJ, we're going to introduce a new record in the surface package because in the end, our CourseRetrievalService will have to return this new type. We click on New Java Class, but instead of class, we'll select records. I will give it the name PluralsightCourse because this record is very tightly coupled to the Pluralsight API, and we want to make this clear in the name of the records. Instead of the class keywords, we get the record keywords in our generated file. And as you can see, there are parentheses after the PluralsightCourse name, which is not something that you have on normal classes. Inside these parentheses, you can declare the so‑called components of the records, and these represent the data points that the record class holds. You can declare them like parameters with a type and a name, and as indicators, we're interested in the id, title, duration, contentUrl, and isRetired flag from the JSON, so we model them as components in the record here. And with this very short record declaration, we actually get a loss. Java will now allow us to instantiate the record through a generated constructor which accepts values for all the components. There are accessor methods to get the values for each component, and the record automatically gets implementations for the equals, hash code, and to string methods based on the components. Let's quickly try this out in our CourseRetriever class by commenting out the retrieveCourses call and instead creating a PluralsightCourse variable that we are going to instantiate using the generated constructor that I mentioned. We have to provide values for all components, and through IntelliJ's autocomplete, we can see all the accessor methods for the components. Note that there are no setter methods, so once a record is instantiated, its values cannot change anymore. It's immutable. Let's quickly add a log statement and pass the course, where in the end, the course to string will be called. And if we run this, we see nicely formatted output for the course that we just instantiated. So overall you get a lot of functionality automatically by declaring just a simple record. In the record declaration, you only have to focus on what kind of data you want to encapsulate in the records, and everything that we just saw is automatically provided by Java. In contrast, let's see what this would look like if we didn't have records. And we would have to write a similar class by hand. We would declare final fields for all of the components, write a constructor accepting values for all the components and assigning them to the fields, and then we would have to write each of the accessor methods, returning the value of the fields. And last, to make this a well‑behaved object in terms of equality of only used fields, we would have to override our own equals and hash code implementation using all the fields that we just declared. And for readability, we could override our own toString methods. That's over 60 lines of code for something that we can do now in a single line in Java 17, and I think that's pretty cool. If you start developing applications using Java 17, it definitely pays off to look into records more. Okay, we're going to remove the temporary codes that showed us how records work because now it's time to change the return type of our getCoursesFor implementation. We don't want to return the raw JSON string here, but in fact, we want to return a list of PluralsightCourse objects. We could just remove string and type list PluralsightCourse here, but remember, we already called the getCoursesFor methods in CourseRetriever so that would then not compile anymore. Instead, I'm going to show you another powerful refactoring that IntelliJ offers called type migration. It gives us the current return type, and we can instruct IntelliJ to migrate this to a list of PluralsightCourse in all places where it occurs. For our application, there would only be two places, that is the return type decoration that we're currently at, and inside CourseRetriever where we call this getCoursesFor method. We then click refactor and get a pretty scary warning because in the end, our method is not yet converted to actually return a list of PluralsightCourse objects. But that's fine. We're going to ignore that for now and fix that ourselves. The interesting thing to note here is that the CourseRetriever class doesn't have a compile error because it was migrated due to the refactoring that we applied, and only the current CourseRetrieval service that we're looking at has a compile error because we're now returning a string, whereas we need to return a list of Pluralsight courses. The 404 case is pretty easy to fix. We can just return an empty list here rather than an empty string. However, the 200 case where we return the string body is not as trivial to fix, so we'll need to spend more time on actually transforming this JSON string into a list of Pluralsight courses. To make the code compiled for now, we're going to cheat a little bit and just return null. At least we now have a PluralsightCourse record that we can target when converting the JSON string. And this is exactly what we're going to do as the next step.

JSON Binding Using Jackson
In the next demo, we're going to use the Jackson library to bind values from the JSON response that we get from the API to our Java Records. With just a small amount of code, we can easily bind values from a JSON response to Java objects. Before we can start using the Jackson library, we need to add it as a dependency to our POM file so that the dependencies are managed by Maven. I'm going to copy in the dependencies that we need, and you can copy the same dependencies from the full application in the Git repository as well if you want to. And as you can see, we're introducing two dependencies, jackson‑databinds and jackson‑annotations. Jackso‑databinds is the library that does the actual JSON to object mapping, and vice versa. But somewhat later, we will also need jackson‑annotation so that we can configure some of the mapping that is happening to tweak it. Since we have two artifacts that belong together and should share the same version, we're going to use a version property again. So we'll have to add a jackson.version property to the property section with the correct value. In this case, version 2.13.3 is the latest version at the moment. We can have a look in the external libraries that IntelliJ to see if everything works. And indeed, we see the Jackson dependencies appearing here as well. The interesting thing, though, is that there are three artifacts, rather than the two that we declared. And that is because Maven also brings in any transitive dependencies. So it turns out that jackson‑databind, for example, depends on the jackson.core artifacts, and Maven understands that we also need this transitive dependency on the class path for the library to work correctly. Now, having Maven pull in transitive dependencies is very useful, but you should not rely on this if you are coding against one of these transitive dependencies yourself in your own code. As a rule of thumb, whenever you use types from a particular library that are in a particular artifact, you should always explicitly list this artifact in your pom.xml and not rely on other dependencies pulling this dependency in transitively. But let's move on now and start using Jackson. If you want to know more about Maven, then you can follow the Maven Fundamentals course on Pluralsight. To use the data binding functionality of Jackson, we're going to have to introduce an ObjectMapper. If you're new to a library, it helps a bit to look around in the documentation of the library. And I'm going to show yet another way of doing this in IntelliJ. If we hover over the ObjectMapper type here, we don't yet get the javadoc for ObjectMapper, and that's because Maven has downloaded the artifact containing all the byte_____ codes for Jackson, but it has not downloaded the source distribution, including the javadoc, yet. By the way, we can also see that the ObjectMapper type comes from the jackson‑databind artifacts that we added to Maven, but that still doesn't tell us too much about the ObjectMapper itself. Now, when you hold the Command key on Mac, or Ctrl on Windows, while hovering over the ObjectMapper type, you can see it becomes underlined and we can click on it, and it actually opens the ObjectMapper. But unfortunately, it's not a real source code that you're looking at now, but it's a view on the code as decompiled from the bytes codesin the class file, and it still doesn't give us any javadoc for the ObjectMapper type. However, IntelliJ offers a Download Sources button, and if you click that, the source distribution of this library will be downloaded from Maven Central. And IntelliJ will give you full access to the source code of Jackson in this case, but it will work for any open source library from Maven Central. As you can see, this includes the javadoc, so you can start learning about the API by browsing the source, and you can start navigating the Jackson codebase inside of IntelliJ as if it were your own code. Now, I cannot overstate how important of a feature this is, because in the end, as a developer, it's also on you to understand the dependencies that you're working with. And of course, this includes reading manuals and documentation. But in the end being able to dive into the source code of a library, looking at the javadoc and the IDE, and even looking at its implementation every now and then is actually a superpower that will help you become a better developer. All right, enough about the Jackson source code. Let's head back to our own code. And remember, we have this PluralsightCourse record defines where we are interested in the id, title, duration, contentUrl, and the isRetired flag, of a course. And our goal is to somehow get this data from the JSON response that we get from the API into a record. The place where we need to do this is in the getCoursesFor method of the CourseRetrievalService. And as you may remember in the 200 OK case, we're still returning null, whereas what we want to return is a list of Pluralsight courses derived from the API's JSON response. So we'll need to do something differently in the 200 case. Let's replace the null by a block because likely we'll have to write more than a single line of code here and start using the ObjectMapper that we just got. Going over the API, there are many readValue variations, where we can provide Jackson with some kind of input and a hint into what type it should deserialize the JSON as the second argument. And then this readValue method will give us back an actual instantiated Java object of that type. We already know that we have a string containing the JSON, so these two overloads are of interest to us. But the first one takes a Class value as a type int, and the second one something called JavaType. Now, the first argument to readValue is easy. We can just give the response.body there. But what should we provide as a second argument to the readValue method here so that we give enough type hints to Jackson to deserialize into a list of Pluralsight course objects? Your first thought might be to provide a list of class value here because we want to get back a list. And this will actually compile and run, but it will not do the right thing because it does not know yet that the elements of this list should be Pluralsight courses. Unfortunately, we cannot provide a generic‑type parameter for lists when we use the .class syntax. So the readValue overload where we provide a string and a Class value is somewhat of a dead‑end street. So let's try the other overloads, where we had something called a JavaType that we could provide. To construct a JavaType that we can provide to the readValue method, we are going to request a TypeFactory from the ObjectMapper, and we're going to ask it to construct a collection type where the first arguments refers to the actual class type of the collection, which is list of class in our case, and the second type refers to the class type of the elements, which would PluralsightCourse for us. And by constructing this JavaType, we provide enough information to Jackson to give us back a list of PluralsightCourse objects. And the idea is, of course, that the response.body, so the raw JSON string, will be parsed by Jackson and will be turned into these PluralsightCourse instances automatically. There's still a small compile error because we introduced a block on the right‑hand side of our case, meaning there's no single expression on the right‑hand side anymore that can be taken as the result value of the switch. So we have to indicate to Java that this last line of the block actually returns the value that we want to return for this case. Now, you might think that we would use the return keyword here, but that is actually not possible because return already means to return from a method. In a switch expression, if you want to indicate within a block that this is the expression that you want to return, you need to use the yield keyword, and now the code compiles. I'm actually still not 100% happy with this code because the other cases, 404 and the default one, consist of a nice single line and single expression on the right‑hand side, but here we have this block, which just doesn't read as nicely. We can easily reflect this by using IntelliJ's Extract Method refactoring, which puts this code into its own private method, which we then call from the right‑hand side of our case. I'm going to give it the name toPluralsightCourses rather than the suggested getPluralsightCourses, and we still have to remove the yield because we now again have a single expression on the right‑hand side of the case. And with this simple refactoring, our code already looks much nicer and more readable. It's time to see how it works out in practice. Before we run the application, I'm going to tweak the final log line a bit and add the amount of courses that we retrieved because we now have a list rather than just a simple string. So that's easy enough to do. Now let's run this. Hmm. This is not what we expected, right? There's an exception telling us there's an unrecognized field status. What is going on here? Well, it turns out that in the default data binding configuration of Jackson, it tries to match all fields in the response of the JSON to the object that we try to deserialize into. However, our PluralsightCourse records only contains a subset of the fields that are in the JSON. And indeed, we didn't define status on our PluralsightCourse records. So this is Jackson telling us that the JSON that it received doesn't exactly match to the objects that it should deserialize into. We can easily fix this by tweaking how Jackson handles these unknown properties. And we're going to do so by introducing the @JsonIgnoreProperties annotation on the record that we define and setting the IgnoreUnknown flag to true in this annotation. This tells the Jackson library that whenever it tries to deserialize into a PluralsightCourse record, it should only look at id, title, duration, contentUrl, and isRetired, and should ignore any other properties that are present in the JSON that we feed it. This annotation comes from the jackson.annotation dependency that we also added in the beginning of this demo. Let's run this application again with the annotation in place. And as you can see, we have a successful run, retrieving 16 courses and printing out all of the courses as nice records.

Filtering Courses
Since we now have a list of Pluralsight courses, we can actually start using them in a meaningful way. And the first thing I want to do is to filter out any retired courses because we're not interested in storing retired courses; we only want the currently active ones. A nice way to do this is by using the stream API that is built into Java. We can turn our list into a stream, and then we can add a filter on the stream, and inside the filter, we can provide a lambda that decides for each element in the stream whether it should be retained or not. So here we can pass a lambda function that takes a course, which is one of the courses in the stream, and then on the right‑hand side we check whether the course is not retired. And if that's the case, we can keep the elements in the stream. Finally, we need to turn the filtered stream back into a list again, and we can do this using the toList method. And if we now run this application again with filtering in place, we see that only 15 courses remain, so apparently there is one retired course. Now we can tweak the lambda that we have in our filter a bit further by using a method reference instead. Now I'm not necessarily saying that what we're going to do now is better, but it is good to see these multiple ways of doing things. So what we can do is replace this lambda by a reference to the isRetired method on PluralsightCourse directly, but that's not exactly the same, because in the lambda, we were checking whether our course was not retired. So we need to do the same here to this method reference and wrap it in a not, which is defined on java.util.function.predicates. The PluralsightCourse::isRetired method reference is effectively a predicate, which takes a course and returns a Boolean. And then the not function on java.util.function.predicate can take such a predicate and invert it. Whether this formulation is better or easier to read than the lambda that we had is quite subjective, but it's good to know that you can encounter this kind of cause. Just to prove that it's the same, we'll run the application again and see that we still have 15 courses in the results. Okay, so we now have a fully functioning CLI tool that makes an HTTP call to the Pluralsight API, turns it into a list of PluralsightCourse objects that we can start using in the rest of our application. If you want, you can start playing around with this a bit yourself by changing the authorId, for example, and retrieving course results for other authors. You can update the run configuration for the CourseRetriever class to provide another authorId as first program arguments. And the way to find these authorIds is to go to the author page of an author at pluralsight.com. So let's say I have searched for JUnit 5 in the Pluralsight library. Then instead of clicking on one of the courses, I'm going to click on one of the names of the authors. This takes me, for example, to the author page of Jim Weaver. And then the final part of the URL here consists of the authorId that you can copy and paste into your run configuration in IntelliJ. Now, I wasn't searching for JUnit 5 by accident because that's the tool that we're going to use in the next demo.

Writing the First Unit Test
In the final demo of this module, we're going to focus on adding tests to our code. We're going to use JUnits for this, which is the most widely used unit testing library in the Java ecosystem. As with many topics in this course, we're not going to dive super deep into JUnits, but you'll get to learn how to write your first unit test in a Java application. For a complete overview of JUnits, I can recommend watching the Java SE 17 Unit Testing with JUnit course. We're going to introduce a method on PluralsightCourse to expose the length of the course as a number rather than a string as we get it back from the JSON response. The API returns the duration in the JSON as a string formatted like one of the examples shown here in the comments, and sometimes it even includes milliseconds. So our goal is to write a method on these records that takes this string duration and turns it into an actual number of minutes. Here we would expect the number of minutes to be 5, as we're going to ignore rounding for now and just look at the number of whole minutes in the course. Let's start by adding a duration in minutes method to the records that will give back a long indicating how many minutes there are in the course. But then the next question is, how are we going to implement this? Are we going to parse the string ourselves and tease it apart? That would be one way to go about it, but it's quite error prone, and it seems like this time that is provided to us is in quite a standardized format. And yes, we can use LocaTime from the java.time package to parse this time. So we'll pass the string duration to this parse method, which will turn it into a local time object that we can use. Now, when you really think about it, the duration that we get back from the Pluralsight API is not really a time, as in a time of day, which is the actual purpose of LocalTime to represent, but it's more of a running time for the course. But by interpreting the running time as a time of day, so in this case, it will be 5 past midnight, we can make use of the java.time APIs to do all the heavy lifting for us, which is quite enticing. A next useful class in the java.time APIs is duration, which has a method between where we can pass two times and it will represent this as a duration between these two times. So what if we provide the LocalTime.MIN constant as a first parameter there, where LocalTime.MIN means all zeros, and we provide our parse duration as the second argument, so the endpoints of the duration. So now we have a duration which spans from zero to the actual running time of our course. The duration allows us to convert it to minutes, and this is what we want to return from our duration in minutes methods. So all in all this seems like a very nice way to turn our duration timestamp into a number of minutes. There's one catch, though. It has to do with what we already discussed. That is, the duration timestamp isn't actually a time of day, but we treat it as such. In our implementation, if a course were to give back a duration with more than 24 hours, this would break. But I think we can live with that for now, because honestly, who is going to watch your course that's more than 24 hours? I know I wouldn't. So overall this seems like a plausible solution, but how do we actually get trust in this implementation and ensure that it works the way we intend it to work? That is where unit testing comes in. Before we can start writing a unit test for this method, we need to introduce JUnit as a dependency in our POM file. And by now we know the drill. So we need to add the right JUnit dependency to our pom.xml, and the only difference that you see here is that we add a test scope to this dependency. This ensures that we can only use JUnit code in our test directory and that we never accidentally start depending on testing codes in our production code. Let's check the external libraries again to see if everything worked all right. And we can see that this JUnit jupiter dependency actually brought in quite a lot of transitive dependencies. And all these transitive dependencies will also have the test scope. Now that we have the JUnit dependency in place, we can start writing a test. We could create this test class by hand in the test subdirectory, but let's use the IDE to do all the hard work for us instead. I'm going to right‑click on the Pluralsight course name and then select Go To Test. IntelliJ notices there is no test yet for this class, and in a very helpful way allows us to create a new test. So let's click that, and it gives us the following prompts. It already preselected JUnit5 as our testing library, since that is already present in our pom.xml file, and the class name of the test is automatically derived from the class name that you're creating a test for by adding test as a suffix. We could change this if we want, but this is a common practice, and it clearly shows the relation between the Pluralsight course records and this test class. Another convention is to put the test class into the same package as the production class. Therefore, the suggested destination package is indeed the same. We can even check a box to generate test methods for any method that we want. In our example, we only want to create a test method for duration in minutes. The other accessor methods we don't even write ourselves, and they just give back the value of the record components, so there's nothing much interesting to test there. After clicking OK, we got a PluralsightCourseTest class in the test directory, and it contains a first test method annotated with @Test. Methods annotated with @Test will be run by the JUnit framework, and their success or failure will be reported as we will see shortly. In order to test our durationInMinutes method, we first need to set up a PluralsightCourse, so let's do that and add in the timestamp that we already saw with 5 minutes and 37 seconds. The most important part of a unit test is the place where you assert a certain outcome. We can use the provided assertEquals method from JUnit to compare an expectation, and let's put in 4 minutes just to see it fill, and the actual value, which is the result of calling durationInMinutes on the course that we just created. We can now right‑click on PluralsightCourseTest and select Run 'PluralsightCourseTest.' And in this case, we're not running a Java application with the main class, as would be the case for a CourseRetriever, but instead we're instructing JUnit to run all the tests in this class. And we immediately see the results, which is a failure as expected. The failure also tells us that we in the test expected to get 4 minutes, and we actually got 5 minutes from durationInMinutes. And that's good because we already knew 4 was wrong, so we can replace our expectation in the test with 5, run the test again, and see that it now succeeds. So adding one test is nice, but what if our timestamp goes over an hour? Does our implementation still work? I'm going to duplicate the test, give it a different method name that indicates what we're actually trying to test here, and then change the string duration to another one that we also receive from the API, but now represents a course that runs for 1 hour and 8 minutes. And this one even includes milliseconds in the duration, which is another variation that we don't want our code to fill on. Of course, we'll also have to change our assertion so that we now expect 68 minutes as the result for durationInMinutes on this course. If we now run the test class again, we see two succeeding tests. Let's add one more test because it's also good to test some edge cases. For example, what would happen if we get back a duration of all zeros? We would hope that our implementation then also just returns zero minutes rather than breaking, but let's find out by creating a test. Again, we duplicate a test, change the name, and update the duration to all zeros. Let's run it to see what happens. Unfortunately, our implementation also covers this. By writing these tests, we now gain more confidence in our implementation, and it also allows us to even refactor the implementation at a later point because we now have tests that check for the behavior of this implementation.

Parameterizing the Unit Test
But it is a bit sad that we now have three tests that we just duplicated and modified a little bit because in the end, the only variation in these tests is in the input duration and the actual expected number of minutes. So, wouldn't it be nice if we could parameterize over those, so that we only write the test once and can provide the inputs and the expected number of minutes as parameters, like this. And the cool thing is that it is actually possible using JUnit5 parameterized tests. So let's clean up the two unit tests that we copied and create one parameterized test using the @ParameterizedTest annotation. Next question is how do we actually provide the various inputs and expected values? There are multiple ways to feed parameters to a parameterized test, but we'll look at one that fits our use case pretty nicely using the @CsvSource annotation, where CSV stands for comma‑separated values. Inside of this annotation, we can use the textBlock property to provide a Java text block that contains all of our inputs and expected values separated by a comma on separate lines. TextBlocks are a relatively recent addition to the Java language and allow you to introduce multi‑line strings into your source code with minimal hassle. I'm going to paste in the three example durations that we had in our tests, and then followed by a comma the expected number of minutes. By using this @ParameterizedTest annotation in combination with the @CsvSource annotation, JUnit will now run the durationInMinutes test three times, once for each line in our textBlock, and it will even convert the 68, 5, and 0, to longs for the expected value that we pass into our method. And when we run this, we again see three successful tests. What are the names of the tests? Now default to the lines provided in the textBlock, making it easy to see which of the lines succeed or fail. We've got our unit tests and everything looks great inside of IntelliJ, but remember we also use Maven to build our application, and therefore Maven should also be able to run our unit tests and fill the builds if there's a failing test. So let's open our terminal again and run the mvn clean test target in this case, which will compile the whole application and the test classes and run all tests. At least that's our expectation. But in practice, it looks like no tests are being run by Maven, as it gives back all zeros for the results, even the number of tests run. The problem that we're running into is quite similar that we had in the first module, where we had to upgrade the Maven compiler plugin to be able to work well with Java 17. In order for Maven to work well with JUnit5 tests, we also need to define a newer version of the Maven Surefire plugin, which is responsible for running the tests. If we set this to 2.22.2, which is the current latest version, and run the same mvn test call again, then we see that actually three tests have run as part of the Maven build as well, and all succeeded, so that's good. And that concludes our demo as we introduce the first unit tests into our application running using IntelliJ and also using Maven.

Summary
Now, you can be quite proud of yourself because we made some major steps in our application. The course info system now has a CLI tool that can actually call the live Pluralsight API and process the JSON response in our Java code. Along the way, we learned how to use Java's HttpClient API, which offers a great way to interact with HTTP servers without including any external libraries. We did have to include an external library to handle JSON in Java Codes. By using Jackson, we were able to automatically map properties from the JSON that we received on two components in the Pluralsight course records that we defined. We didn't have to write any parsing codes or dive into the structure of the JSON. Everything was handled for us automatically. Last, but definitely not least, we introduced tests in our code using JUnits. Writing unit tests is a great way to ensure that the code that you write does what you need it to do, and the tests will stay with you even if you change the implementation so that you can be sure that it behaves as expected. So all in all, great job, but now it's time for the next challenge, storing our courses in a database.

Storing Data in a Database
Overview
In the previous two modules, we learned how to set up a Maven‑based Java project and implemented a CLI tool that retrieved data from a real Pluralsight API. Pretty cool already, but we can do even more. We've written quite some code to get our CLI tool off the ground, and now it's time to make sure the data we retrieve sticks around by putting it in a database. Let's look at the big picture of what we're building again. We already covered the CLI tool. In this module, we're going to introduce a repository abstraction that can store courses. As you can see, this repository will also be used by the server later on to retrieve courses, which puts us in a tough spot. We can add the database code to our CLI tool, but that will make the server depend on our CLI tool codes, which isn't great design. So we'll do some work to modularize our code base and ensure we have a clean separation between all three components. Then we can make the repository a shared component used by both the server and the CLI tool. Next question is, how will we store data in the repository implementation? Nowadays, you have many options for persistent storage, but relational databases are still the workhorse of our industry. In our application, we'll use a lightweight SQL database called H2, which itself is also written in Java and can be easily integrated into our projects without any external installation. We'll dive deeper into H2 later in this module and also into the repository pattern that we want to apply. But first, let's modularize our code base before writing the repository code.

Refactoring to Multiple Maven Modules
Currently, all our codes is part of a single Maven module. When your application grows, it makes sense to group related parts of the code base in separate Maven modules. This is possible by introducing a parent POM and creating multiple submodules that point to this parent POM. Every module has its own pom.xml file and can be built separately, resulting in their own .jar file. Code in a module can only use code from another module if there's an explicit dependency in the POM file. This helps you as a developer to structure your code base and avoid your application devolving into a large spaghetti code base, where everything is tied to everything else. Through the setup, you can share configuration across submodules by defining it in a parent POM. Also, when you express dependencies between submodules, Maven will take care of building them in the right order automatically. I must warn you that turning a single module Maven builds into a multi‑module Maven build using IntelliJ is going to be a bit fiddly. And to be fair, if you're going to create a multi‑module Maven builds, you'll often do it from the start. However, I promise you, we will be building this application together from scratch. So let's do this. IntelliJ will help us for a big part, even though it can also get a little bit confused by this refactoring, as we'll see later, but nothing that we can't fix. The first step is to right‑click on a project and select New Module. We're first going to create an empty module, course‑info‑repository, which will host the code that we're going to write later. Java and Maven are already pre‑selected, and IntelliJ also selected our course‑info‑maven projects as the parent, which is exactly what we want, so that course‑info‑repository becomes a submodule of our course‑info project. Let's click Create, and a new course‑info‑repository subdirectory appears in a project. Expanding this directory, we see the familiar Maven layouts with a pom.xml file and a src folder. This is where we can start writing our repository code later on. In the new pom.xml file that was generated for the submodule, we can see that it has parent elements, pointing to the already existing pom.xml file in the top‑level directory by artifactId, groupId, and version. There's also an artifactId for this submodule containing the name that we defined. Interestingly, there's no groupId or version defined in this POM. If you leave those out in the submodule, it will inherit the groupId and the version of the parents, which is fine for our purposes. Let's remove the old style Maven compiler properties again, just as we did in the original pom.xml file, since this submodule already inherits the correct compiler configuration from the parent POM. And now this new Maven submodule is ready to be used. Introducing this submodule also changed a few things in the top‑level pom.xml file. A new packaging element was added containing the value pom, which overrides the default packaging, which is .jar for a Maven module. In essence, this means that the top‑level pom.xml module will not produce a .jar file anymore. The goal of this parent POM is now to contain shared configuration between all of the submodules. The second change is the addition of a modules elements containing a nested module referring to our course‑info‑repository submodule. This is done in Maven to aggregate modules, meaning that if we invoke any Maven commands on the top‑level POM, they will also be executed on the modules listed in the module section. So on the one hand, we have the pom.xml file in the submodule referring to this parent so that it can make use of the shared configuration that we have here. And on the other hand, we have this top‑level parent POM referring to all the submodules so that it can be built together. Now let's introduce a second submodule for our existing CLI codes. We can use the same new module functionality, only now we're going to call the submodule course‑info‑cli. And again, we get a new subdirectory course‑info‑cli containing the Maven source layouts and a new POM file. We'll also remove the generated compiler properties here, but this pom.xml file cannot stay empty because we're going to move our existing codes into the submodule, which means that we should move the dependencies that we declared in the top‑level POM to the submodule because every submodule can have its own dependencies. So let's select the dependencies section from the top‑level POM. Got it. And paste into the POM of course‑info‑cli. Let's also move the version properties to the course‑info‑cli POM so that they're close to where they're used. Now for the slightly more tricky part. We're going to remove the empty source directory from the new course‑info‑cli submodule, and we're going to move our existing top‑level src directory into this module by dragging it there. This all seems to work nicely, but unfortunately, this moving of src directories has IntelliJ a little bit confused. We can see this by opening the PluralsightCourseTest and running it, because it doesn't run. It just fills with a class not found exception. We can fix this, though. Let's right‑click on the top‑level course‑info project, select Open Module Settings, and make sure that course‑info is actually selected, not course‑info‑cli or course‑info‑repository. Then remove the first three entries on the right‑hand side. So, src folders, test src folders, and resource folders. Then we click OK and try running the test again. Fortunately, all is well now. As I already mentioned in the beginning, turning a single Maven module into multiple Maven modules within IntelliJ is not something that you will do often. And if you do so, you might run into quirks like this. Another thing you will see is that if you try to run the CourseRetriever class again, there's no run configuration anymore providing a program argument. To fix this, right‑click on CourseRetriever, select Modify Run Configuration, and add a course author as program argument again. In some cases, you may also have to select course‑info‑cli as the class path project for this run configuration. And after updating the run configuration, we can run the CourseRetriever again, and it still works. Now, there's one more thing we need to do in the pom.xml file of the course‑info‑cli submodule. We're going to add a dependency to the course‑info repository submodule, because in the end, we want to be able to use the repository from our CLI tool. And for that to work, we need to explicitly add this dependency. We now have a top‑level POM and two submodules, and it all seems to work in IntelliJ. But what about our actual Maven builds from the command line? Let's try that out by running mvn clean verify from the top‑level course‑info‑directory. Fortunately, the Maven build is also successful, and we can see in the summary that it builds all three modules. When we scroll up a little bit, we also see that the tests are still running as part of the Maven build, which is also good. Finally, if we look into the target folder of the course‑info‑cli submodule, we can see that a .jar file is emitted containing the compiled code of this submodule. Looking at the top level of our project, we can see there's no target folder anymore for the top‑level course‑info‑pom. That is due to the change of packaging in the top level pom.xml file, as we discussed before. It changed from the default .jar packaging to POM packaging, which means that the top‑level module doesn't produce artifacts anymore, but it is just there for shared configuration. Now that was quite a bit of work, but we did make big steps into structuring our application better. And we're now ready to write code for our repository.

Introducing the Repository Abstraction
We're now ready to start the implementation of the repository. But you may be wondering what is this repository abstraction that he's talking about? Our goal is to introduce an abstraction or API that hides the actual position storage implementation details. Everywhere in our code where we want to store or retrieve courses from the database, we'll be able to use this CourseRepository abstraction rather than talking to the H2 database directly. This way, the consumers of the CourseRepository API don't need to know anything about SQL queries or the way the data has to be stored. This approach has several advantages over doing direct database access. By using the repository API, our code can be written in terms of domain abstractions and not in terms of a specific technology. And by hiding the implementation details of the persistance technology inside of the repository implementation, we can, if we want, change the underlying database technology without affecting or requiring changes in the consumer of this repository API. We'll also see that by introducing a CourseRepository API, we make the application more testable without requiring an actual database. Before we are going to introduce the CourseRepository interface, we're going to create a new record to represent a course in our system. You may think, didn't we already have this Pluralsight course records in the course‑info‑cli module? And you're right. However, that is a specific representation based on the data that we get back from the PluralsightCourse API. We don't want to use that as a central domain object in the rest of our system. Because in the end, we want the system to be able to store arbitrary courses and not just the ones that are coming from the Pluralsight API. Also, the repository module doesn't have a dependency on the CLI module, and it shouldn't, so we cannot use PluralsightCourse here. In fact, the dependency is the other way around. The CLI module has a dependency on our repository module. The course record we will introduce here represents our core domain. This means later on, we'll need to do some translation in our CLI projects when storing the Pluralsight courses, but we can deal with that when we need to. We're now going to focus on creating an independent domain object that we can store in the database. We'll give the record four components, an id, name, length, and a URL. Now, we could leave it at this, but if you're creating a domain object, it's also good to think about validation of data that's part of this object. What if, for example, if we want to prevent null values or empty strings being passed as an ID or name? We can validate this in the constructor of the records. And one nice feature of records is that you can declare a compact constructor, where you don't have to list all the constructor parameters because they would be the same as the components that we just listed in the definition of the records. Yet, in this complex constructor, we can still refer to id, name, length, and URL because they're implicitly there. I'm going to bring in a helper function called fields where we pass a string and check whether it's null or blank, and if so, throw an exception. We can now call the field method for all three strings that are passed to the constructor. Now that we've written this, it will be interesting to test this code. However, remember we're in a new Maven submodule, so the pom.xml doesn't declare any dependencies yet. In order to write a unit test, we again have to add JUnit dependency to the POM. I've brought in the course test file from the solution on GitHub, and I'm not going to show it because I will leave this as an exercise to you. Can you write test codes for the course that we've just written, testing the validation code? As a hint, rather than using assert= as we did in the previous test that we wrote, look into JUnit's assertThrows method, where you can check whether a particular piece of code throws an exception. Meanwhile, we'll continue with introducing the actual course repository interface by creating a new Java interface. We're going to declare two methods in this interface. The first one is saveCourse, where we pass a course so it can be saved in the database. And the next one is getAllCourses, which should retrieve all courses from the database and give them back in a list. You can see that this CourseRepository interface doesn't contain any details about the database that we're using. There's nothing about SQL queries here, about database connections, etc. The interface is completely expressed in terms of our course domain objects. Now all that's left for us to do is to provide an actual implementation for this course repository interface.

Setting up the Repository with H2 & JDBC
Before we create an implementation of the course repository interface, let's dive a bit deeper into the H2 database and JDBC. H2 is an embedded SQL database written in Java. This means we won't have to install a separate database server, like with Postgres or with SQL Server, but we can include H2 as a library in our application, and it will run alongside the application in the same process. For persistence, H2 writes all data to disk in a file. Other than that, to your application, it acts as a normal SQL database server where you can create tables, store data, and query. H2 also features a mode where other applications can connect to this embedded database running in your application. Since we will also be writing a server application in the next module that also needs to use the repository, we'll be making use of the so‑called auto‑server mode of H2. And then theres JDBC. JDBC is part of the Java standard library and offers a way to connect to any SQL database in a standardized manner, as long as the database provides a JDBC driver. JDBC stands for Java database connectivity, and virtually all relational databases provide a JDBC driver, and H2 is no exception. With JDBC, we have a standardized Java API to interact with any SQL database, and we don't have to worry about tying ourselves to a particular API of a certain database vendor. It's also good to note that there are many Java libraries out there that build on top of JDBC to offer even richer positioned APIs. One well‑known example is Hibernate, which offers object‑relational mapping, and Jooq. For our use case, those are overkill, and we can just use JDBC directly without having to integrate yet another third‑party library. We're now ready to implement the CourseRepository interface, and of course we need to start by bringing in the right dependency. So let's open the pom.xml file of course‑info‑repository and add the dependency to H2. We can now create a class called CourseJdbcRepository, indicating in the class name already that this is a technology‑specific implementation of the technology‑agnostic CourseRepository interface. In this setup, at some point, we could introduce an alternative implementation using a different database technology, but we won't go there. Let's first get this JDBC implementation up and running. The class needs to implement the CourseRepository interface that we created, and we can use Alt+Enter selecting implement methods to quickly get steps for the two methods that we want to implement. We're not going to implement the methods yet because we do need a bit of setup first. A central element in JDBC is a data source, which represents a database that we want to connect to. After adding these fields, we'll create a constructor to initialize it. We instantiate a JDBC data source, which is a type coming from the H2 library. And on this data source, we need to configure a URL, which points to the database. Let's introduce a constant for that, and I'm going to paste in the JDBC connection string here. There's a few things to unpack. First of all, we indicate that we intend to connect to an H2 database of JDBC. Next, we need to provide a file name where H2 will store its data, but we want hard‑coded. Instead, I'm putting a %s placeholder there so that we can later configure the file name. After the semicolon, we provide a few configuration options to the H2 database, enabling the other server modes so that other processors can also connect to this database and configuring that we want to run a script on the initialization of the database from the db_init.sql file, which we will bring into this project later. For other databases where you are running a separate database server, such a JDBC URL would also include the location of the database server. But since H2 is an embedded database running in our own Java process, we only need to configure a file name. Then we assign the JDBC data source to our data source fields, and most of the setup is done. As I mentioned earlier, we also need a db_init.sql file. I'm going to copy the file from the solution in the GitHub repository and paste it into the top‑level course‑info directory. This SQL script ensures that a table is created if it doesn't exist yet where we can store the id, name, length, and URL of a course, but also in those fields which we're going to use in a later module. However, since it's a nullable column, it won't hurt us for now, even if we're just going to use the first four fields.

Implementing the JDBC Repository
Now that we have the CourseJdbcRepository class set up, we can start implementing the two methods that we're interested in, saveCourse and getAllCourses. So let's get ready to write some code to fire off SQL queries to the database. We'll start with the saveCourse implementation. First thing we need to do is to acquire a database connection from the data source. By using the getConnection method, we obtain a connection that we can use to interact with the H2 database. Whenever you create a connection this way, it will be in a mode called auto‑commits, meaning that every command we send will be automatically wrapped in a transaction and committed, so there's no need to write any manual transaction handling codes in our implementation here. There's a red line under getConnection because we don't yet handle an exception that it froze, but we'll get back to that later. First, we will create a prepared statement by using the PreparedStatement method on connection. We need to pass a SQL statement a string to the method, so we'll use a constant INSERT_COURSE to contain the SQL code for inserting courses. I'm bringing in the SQL statements as a text block again because then we can easily split it over multiple lines, and it's still nicely readable. There are a few things to note about the SQL statements. First of all, I'm using merge rather than insert into for the table. This way, we will get so‑called absurd behavior for records in the database, meaning that it will create a new record if no course exists yet for the given ID. And remember ID is the primary key of the courses table. But if we're using this merge into on a course that already exists in the database, then all of its fields will be updated with a new value. The other thing to note is that we're not passing concrete values into the SQL statements, but rather four question marks, which act as placeholders in a PreparedStatement, and we can later provide the actual values when executing the statements. By using the PreparedStatement API this way, we can prevent so‑called SQL injection attacks, which you would be vulnerable to if instead you were creating the SQL string yourself by concatenating the values to the string without escaping them. Don't worry if this doesn't make too much sense to you now, but just remember to use this placeholder syntax and the PreparedStatement API to craft SQL statements rather than creating a SQL statement industry yourself. After creating the PreparedStatements, we still need to provide the actual values to be inserted, and the PreparedStatement offers various setters to set values of different types. The API uses an index to refer to the placeholders, so we're passing the course.id on index 1, which is the first placeholder, the course.name on index 2, and so on. Finally, we need to execute the statements, at which point the prepared statement will be sent to the database to be executed. Now, we still have a lot of red lines in our code due to SQL exceptions that can be thrown by these methods, which we don't handle yet. We don't want to add throw SQL exception to our method because that would violate the repository pattern that we talked about earlier by exposing the fact that we're using a SQL database underneath. So we'll need to handle this differently. Let's first add a try catch to catch the SQL exception. So what to do if a SQL exception occurs, because we can't really recover from it here, either. We still want to throw an exception to our callers, but it should be an exception that we control ourselves. So let's introduce a new exception called RepositoryException. We can just start typing throw new RepositoryException and also wrap the original exception, and then use IntelliJ's quick fix with Alt+Enter to actually create the class. It gives us this template for an exception, and we'll make it work for us by calling super in the constructor and changing the extends Throwable to extends RuntimeException so that it becomes a RuntimeException, meaning that we don't force the users of our repository API to always have a try catch around every method invocation. That is enough to make this code compile, and it would work, but there's still a subtle issue here because we are opening a database connection with the getConnection methods, but we're never really closing it. Opening a database connection takes resources, and if we don't close the connection in a timely manner, we might run out of resources at some point. Fortunately, a JDBC connection implements the also closeable interface, which means that we can use it inside of a try with resources statement, which looks as follows. We hoist the connection decoration into a top‑level try so that it can be used in the body, and it will be automatically closed at the end of the body after statement.execute, and crucially, it will also be closed if an exception occurs. This way, we ensure that we don't leak connections with its associated resources. As a side note, in a production‑grade application, you'll typically also see some form of connection pooling, as closing and opening connections for every request to the database is quite expensive. However, for our purposes, the pattern that we use here works well enough. Now we still need to implement getAllCourses. The basic format of these methods will be quite similar to what we did in saveCourse, but rather than using a SQL merge statements, we're going to do a query where we retrieve information from the database. We'll copy the connection setup with the try statement, and again, add a catch for SQLException, which will now have an error message saying Failed to retrieve courses. Then inside of the try, we can implement our logic. Rather than using a PreparedStatement, which can carry placeholders, we're going to use a simple statement by using connection.createStatement. Then on this statement, we can invoke executeQuery, where we can pass in a SQL query as a string parameter. All we need is a simple SELECT* FROM COURSES here. Since this is a SQL query, we will get back information in the form of a ResultSet. By introducing a ResultSet variable, we can inspect the results. We can iterate of the ResultSet using a while loop and resultSet.next. And in this while loop, we want to accumulate all courses that have been returned. To do so, we'll introduce a courses variable that contains all courses that have been found so far and initialize it with an empty array list. Starting with the outcome in mind, we can already write courses.add course as the final statements in our while loop, but now we still need to take the information from the ResultSet and turn it into a course. We can instantiate the course records by taking the ResultSet and getting out all of the values for the current row using a similar index‑based API on the ResultSet that we also saw on the PreparedStatement earlier. So getString(1) takes out the id, getString(2) returns the name of the course, getL(3) will give back the duration in minutes, and finally, getString(4) will return the URL of the course. Now we still need to change to return null to return courses, and there we have the implementation of our getAllCourses method. As a final tweak, let's also wrap the lists that we return in Collections.unmodifiableList. Otherwise, the caller of getAllCourses will be able to mutate a list that was returned, and it wouldn't accurately represent the result of the query anymore, which is something that we would like to prevent. By wrapping it like this, we ensure that the collection cannot be modified anymore by the caller. We now have a JDBC‑based implementation of our very technology‑agnostic CourseRepository interface, but we can go even one step further. At the moment, the CourseJdbcRepository is a public class, and we would like to hide this class as an implementation detail. So let's remove the public so that it can only be used from within this package, which means that other parts of our application can never refer to CourseJdbcRepository directly. We only want to expose the CourseRepository interface, which is completely defined in terms of our domain and not in terms of a specific technology. You might be wondering how users of this API will actually get an instance then of this class, but we'll get to that later. For now, this is strong encapsulation in action.

Using the Repository
Now it's time to start using the CourseRepository implementation that we just created inside of the CLI. We will create a CourseStorageService class alongside the CourseRetrievalService class that's responsible for storing courses that we have retrieved. Inside this CourseStorageService, we introduce a CourseRepository field. Remember, we can use the CourseRepository codes in the CLI module because we have a dependency to the repository module. Let's generate a constructor that initializes the fields, and we can worry later about where the CourseRepository comes from or which implementation is passed to this constructor. We can now implement the method storePluralsightCourses that takes a list of PluralsightCourses, so these are PluralsightCourse record instances that are returned from the CourseRetrievalService, and we want to use the CourseRepository to store them as courses in the database. We can do this easily by looping over the PluralsightCourses, invoking courseRepository.saveCourse for a course, but then we still need to translate the PluralsightCourse records into a course record that is used by the repository. We can invoke the course constructor passing in the id, the title of the PluralsightCourse, and also the duration in minutes, which we already implemented on the PluralsightCourse records. But we also need to provide a URL as fourth parameter. Looking at the data returned from the Pluralsight API, the URL provided there is only partial and only provides the path of the URL. Therefore, I'm going to add a PS_BASE_URL constant to this class that we can use as a prefix to turn the partial contentUrl provided by the Pluralsight API into a full URL that can be used by anyone. As a side note, if we are going to store many courses at once with this method, it might pay off to add a repository method that can insert courses into the database in bulk. But since each author only has a limited amount of courses, we can just use this naive_____ looping approach and call courseRepository.saveCourse repeatedly. Remember how I mentioned that introducing the repository interface also increases testability? We can see this in practice by implementing a unit test for this CourseStorageService where we won't use the actual implementation of the CourseRepository interface that we just created so that the unit test for this class doesn't have to use an actual database. Let's use the go‑to test trick again to create a unit test for this class, indicating that we want to test methods for storePluralsightCourses. And the first thing we're going to do inside of the unit test is to instantiate the CourseStorageService class. However, that means that we need to pass a CourseRepository implementation to this class. Let's introduce a local variable for that. But then how do we instantiate an implementation for this interface? We can't instantiate the CourseJdbcRepository class because, remember, we removed public from this class, so it's not accessible outside of its own package, which, by the way, is also what we intended because we don't want to leak implementation‑specific knowledge of this class to consumers of the CourseRepository API. What we can do, however, is create a fake implementation of this CourseRepository interface for testing purposes here in this unit test. So I'm going to define an in‑memory CourseRepository class which implements CourseRepository, and it will just contain a simple array list where we can put courses and retrieve them at a later time. No database involved. Everything happens in‑memory. In the saveCourse implementation, we simply add the course to the list, and in getAllCourses, we return the list of courses that we already have. We now instantiate the in‑memory CourseRepository so that it is passed to the CousreStorageService implementation. Of course, we also need to set up some test data to use in this test. So let's create a PluralsightCourse instance with some test data, and then we'll call the storePluralsightCourses method on the CourseStorageService with a list containing this PluralsightCourse. What we're interested in is testing that the CourseStorageService does a correct translation into a course that can be stored in the CourseRepository. That's why I'm creating an expected course instance which has the same id, same title, but it has a duration in minutes as calculated from the PluralsightCourse, and the full URL as it should be created by the CourseStorageService. Then we can write the assertion using assertEquals where we expect a list just containing the expected course if we call getAllCourses on the repository, which is the in‑memory CourseRepository in this test. Without using the actual CourseJdbcRepository implementation, we can test that the CourseStorageService interacts well with the CourseRepository and does the right transformation when turning a PluralsightCourse into a course. The unit test runs successfully to prove this. Instead of writing our own in‑memory CourseRepository implementation for this unit test, we could have also used a so‑called mocking library. Mocking libraries are generic libraries to mimic behavior of external interfaces to the unit test, but diving into this practice goes far beyond the scope of this course. Although, I definitely recommend looking into mocking libraries like, for example, Mockito, if you're serious about writing unit tests. Okay, we now have a test of our CourseStorageService, but we still haven't really used our database implementation. And you're probably wondering how we're going to access the CourseJdbcRepository implementation if we can't access it from the CLI. We'll get there, I promise. So let's switch back to the production code again and go to the CourseRetriever class because that's where we're going to use the CourseStorageService. But as we know, before we can instantiate the CourseStorageService, we first need a CourseRepository implementation, and we know we cannot instantiate the CourseJdbcRepository class. That's why I'm going back to the CourseRepository interface and I'm going to add a static factory method that is responsible for instantiating the CourseJdbcRepository implementation. It also needs a database file parameter so that we can pass it to the CourseJdbcRepository constructor. The twist to the story is that the CourseRepository interface is in the same package as the CourseJdbcRepository implementation class, so we can instantiate it here. However, the return type of the static factory method on the interface is CourseRepository, so we're still not leaking details about the implementation. The caller of the static factory method only knows that it gets some implementation of the CourseRepository interface, but it doesn't know and it doesn't have to care about the actual implementation. So we can use our new openCourseRepository method and pass in courses.db as a database file to use. And with that, we can instantiate the CourseStorageService, passing in the CourseRepository. Since we already have the coursesToStore list, we can simply invoke storePluralsightCourses on the courseStorageService and pass the coursesToStore, and that should take care of storing them in the database. We can wrap up with a final log line, which says that courses are successfully stored. Let's run the application and see what happens. We're still retrieving the courses from the Pluralsight API as before, but we also see the log line "Courses successfully stored," which means that our CourseStorageService has been invoked and the courses should be in the database. However, the application has ended, which also means that the database has been shut down because it runs as part of the application, and we only have the courses.db.mv.db file as a witness that at least something happens in terms of database interaction. I can open this new file, but of course, it doesn't look pretty because it has its own custom format to store the data. But scrolling down a bit, I do see a lot of information about Pluralsight courses, which means that storing the courses through our CourseStorageService using the CourseRepository implementation seems to have worked nicely. Of course, it would be much nicer to expose the information again in a readable format. And that's exactly what we're going to do in the next module, where we are going to build a server that will expose the information that we have in the database through an HTTP endpoint that will serve JSON for all of the courses that we've stored in the database.

Summary
In this module, we learned how to store data in a relational database and extended our system to store the RetrievePluralsightCourses inside of an H2 SQ L database. We introduced a repository pattern to do so. The repository pattern allows us to hide implementation details of the underlying persistence mechanism so that consumers of this repository API can write clean codes that does not contain any implementation details. The API of a repository is expressed completely in terms of domain objects and not in terms of low‑level technical details, like SQL queries or database connections. This also means that you will be able to change the implementation, maybe even change the underlying database, without affecting consumers of the repository API. Finally, we also saw how the introduction of the repository interface makes the system more testable. In the implementation of the repository, we used JDBC, the Java database connectivity API that is part of the JDK. The H2 database provides a JDBC driver, as do almost all databases. If you're working with the Java application that uses a relational database, it's almost guaranteed that it uses JDBC for the interaction with the database. Of course, from the application sites, you might choose to use a higher‑level library, like, for example, Hibernate, which layers on top of JDBC and offers features like object‑relational mapping out of the box. If you want to learn more about JDBC, you can watch the Java Core Libraries: JDBC 4 course on Pluralsight. For now, we've seen enough of JDBC, and we're moving on to exposing our data as JSON over HTTP so that we expose a true API for our course‑info system.

Creating a REST API
Overview
So far, we've built a system that can call Pluralsight's API, transform the response, and store it in the database. That's already quite something, so well done for making it here. In this module, we're going to extend our course info system to also expose this data over a REST API. We'll do that by creating a server component with the REST API that can be used by other developers to interact with the course info system. It will reuse the repository module that we already created as a back end for this API. I'm not going to explain what REST exactly is or debate the various approaches to REST. I'm going to assume you know the basics here already. So if not, it might be good to read up on that before moving on. We are going to look at how to implement two HTTP endpoints, one to retrieve courses at JSON, and later on to add notes to courses over this REST API. How can we do this using Java? There are various approaches possible, but we will use JAX‑RS. JAX‑RS is an API specification coming from Java EE, the enterprise Java specification, now known as Jakarta EE. This specification is designed to build RESTful APIs in Java. But JAX‑RS itself is only an API, and we also need an implementation of this specification to serve and run the API. For that, we're going to use Jersey, a JAX‑RS implementation hosted by the Eclipse Foundation. As an aside, the Eclipse Foundation has taken over the Java EE specification under the name Jakarta EE and is now responsible for its development, and this includes JAX‑RS.

Creating a JAX-RS Resource
We're going to create a JAX‑RS resource class in this demo. A JAX‑RS resource is a Java class describing and implementing a REST API that can later be accessed over HTTP. Before we can implement our resource class, we're going to introduce a third and final module for this application. We're going to call it course‑info‑server, as this will be the server component of our application serving the API. We've done this before, so it's no surprise that we now get a course‑info‑server directory containing the Maven source folder layout and a new pom.xml file. As we know by now, we can remove the properties that were generated by IntelliJ in this pom.xml file, and we're ready to write some code. Well, not completely, because we don't have any dependencies yet in our POM file, so let's address that first. To get started, I'm going to copy some basic dependencies from our CLI projects since our server will also have a dependency on course‑info‑repository and SLF4J for logging. Now, I know copy pasting doesn't feel great, so in the next module of this course, we'll look at a way to actually improve our Maven setup where we can share a bit more between our POM files. But for now, we'll stick with the straightforward copy and paste. Copying these dependencies means that we also need to copy the slf4j.version property. So let's also bring the slf4j.version property into the pom.xml file of course‑info‑server. We're nearly there, but if we're going to write a JAX‑RS resource class, we need to add a dependency to the JAX‑RS API first. And we can do that by adding a dependency on the jakarta.ws.rs‑api artifact. All right, we now have everything in place to create our JAX‑RS resource class. We're going to call it CourseResource because it will be an API revolving around our course domain object. First thing we're going to do is to add a path annotation. This means that any endpoints we define in this class will be hosted under /courses. We can extend the path and methods of this class later, but every endpoint defined in this class will at least have /courses as its prefix in the path. Let's bring in the logger so that we can use it later. And we also need to add a CourseRepository field to this class because we already know that in the endpoint that we're going to implement, we want to return courses ultimately as JSON, and therefore, we need to be able to retrieve courses using the CourseRepository. Okay, after all this setup, we're ready to write the endpoint implementation. In JAX‑RS, we can simply introduce a method, let's call it getCourses, with a return type that will ultimately be returned over HTTP. Our goal is to return proper JSON for all courses. But let's start a bit simpler by just returning a string representation of our courses so that we first get our endpoint up and running and test it before moving on to exposing JSON, because as it turns out, that requires a little bit more work. Now we need to retrieve our courses and turn it into a string. We can do so by calling stream on the list that we get back from getAllCourses, map every course to a string, and then use the collect method from the streams API, passing in a collector that joins all strings in a stream separated by a comma and a space, and returns it as a single string. We're almost there, but if we want to expose this method over HTTP, we need to indicate using the JAX‑RS API which HTTP method and path this method should be bound to. Since this will be an API call that only returns information, we're going to expose this method using the @GET annotation. I'm not going to add an additional path annotation, meaning that this method will be bound to the path /courses, and whenever the server will receive a GET request to /courses, it will invoke this getCourses method and return the string that we create here to the caller. But speaking about the server, how is this actually going to work? Because we now only have a simple Java class with some JAX‑RS annotations, but that doesn't do anything on its own. As we said JAX‑RS is only an API, and it needs an implementation that hosts this CourseResource and provides an HTTP server. Jersey is one of these JAX‑RS implementations, and as a next step, we're going to introduce Jersey into this module so that it can serve this CourseResource API and we can make a real HTTP call that will end up in this getCourses method.

Exposing a JAX-RS Resource over HTTP Using Jersey
As you probably already expected, before we can start coding the server that will host the CourseResource class, we will first need to bring in the right dependencies. It turns out that for a minimal Jersey setup that can host JAX‑RS resources, we need three additional dependencies. Jersey‑server, which is the core component, jersey‑container‑grizzly2‑http, which is a specific HTTP server implementation that Jersey can use. There are others, but this one works fine. And jersey‑hk2, which is Jersey's own dependency injection framework that is required at runtime, but we're not going to use it. So we'll give it a runtime scope so that this dependency is available at runtime, but we will not code or use this hk2 dependency injection framework in our code. Since all three artifacts share the same version, we're going to use a property again. And by introducing this version property, everything is in place to start using Jersey. We'll create a new class called CourseServer and give it a main method, since we want to run this separately from our course‑info‑cli tool. Let's bring in a logger for good measure and start our main implementation with a log message telling that we're starting the HTTP server. Now, remember, in order to create a CourseResource instance, we need a course repository. Fortunately, we already defined a dependency in our POM file to the course‑info‑repository module, so we can use the openCourseRepository factory method that we created there. We're going to pass in the same database name so that the courses that we retrieve using the course CLI tool will be visible in our server. To initialize the Jersey JAX‑RS implementation, we need a ResourceConfig. We can instantiate it and then call register, passing in our CourseResource, which we can instantiate by passing in the CourseRepository that we just created. When you think about it, we're effectively doing a form of manual dependency injection so we're passing the CourseRepository to the CourseResource. And this closely follows a pattern that you often see when dependency injection frameworks are used, such as Spring. However, there the instantiation of classes and passing of dependencies is completely handled by the dependency injection framework, often steered by adding annotations on classes. In our course‑info application, I prefer to write straightforward and explicit codes. But of course, as applications grow, this trade‑off may become different. And in most larger Java applications, you will see a dependency injection framework being used. In the end, just remember that it all boils down to the simple pattern of passing independencies into classes, like we do here to improve testability and decoupling between components. As a final step, we're going to create an HTTP server where we are going to pass this configuration. We're going to use the Grizzly dependency to create this HTTP server through the createHttpServer method on GrizzlyHttpServerFactory. First, we need to pass in the URI that contains the host name and port that the server will listen on. In our case, we're going to listen on localhost port 8080. As a final parameter, we're going to pass in our resource configuration. And that's all the set up we need to run a JAX‑RS API on the Jersey implementation. So let's run the CourseServer class to see if it works as expected. First of all, note that the Jersey implementation also does some logging next to our application logging, and it looks a little bit different. That's because we do our logging through SLF4J with the SLF4J simple backend, whereas Jersey is logging through the JDK logger API. We'll come back to this in the next module and see how we can unify this into a single logging format. Second thing to note is that this application doesn't terminate, which makes sense because it's a server and it needs to keep running, listening for incoming connections. If you do want to stop the CourseServer class, just use your red stop button on the left. Finally, if you're a bit unlucky, you might see an exception that some other server process is already listening on port 8080 on your machine. In that case, either find the auto‑process and shut it down or change the port in the base URI constant to a port that is free on your machine, and start using that. Let's head to the browser and see if a GET request to localhost:8080/courses actually ends up in our CourseResource endpoint and calls the getCourses method. After hitting Enter, we see all of our courses in a single string, and that's exactly what we wanted to see. At least, that's what we wanted at first. But of course, rather than having the string representation of our records, we want to turn it into proper JSON so that it can be consumed by other applications and tools. So our next challenge is to not return a string from this endpoint, but Jason.

Returning JSON with JAX-RS and Jersey
We're going to move back to the CourseResource class to see if we can change the getCourses method to return JSON rather than a string. If you look into the JAX‑RS implementation, it is not required to return a string from a method annotated with the JAX‑RS annotation, like our getCourses method, which is annotated with the @GET annotation. We can also return other objects, and the JAX‑RS implementation is responsible for turning this into an HTTP response. So let's just try the simple and naive approach where we replace the string return type with a list of courses. We could either remove our stream pipeline completely and just return the result of getAllCourses, but I also want to add sorting to the result that we are returning from getCourses so that our API has a stable order of courses. Let's sort on the natural order of the ID of a course by creating a comparator like this. Then we still need to call two lists on a stream to turn it into a list. To test this out, we need to start the application if it's not running, or restart it if the server was still running. As you can see, the server here is still running, so I'm going to use the Rerun button. This will terminate the existing course server process and start a new one. We can go to the browser, click Reload, and see that we get back an HTTP error 500. That's not quite what we want. Going back to the server, we see an error message logged at the severe level telling us that there's no MessageBodyWriter found. But the interesting part is that it mentions media type is text/plain, so effectively it's telling us that it cannot turn this collection into a plaintext response. But then again, we don't want a plaintext response. We want to return JSON. And it turns out that in JAX‑RS, you need to use the @Producers annotation to indicate the response type that should be produced for this endpoint. In the @Producers annotation, we're going to tell that we want to generate JSON by selecting MediaType.APPLICATION_JSON. Let's restart the application again, head back to the browser, and click Reload filled with expectations. Unfortunately, we're still getting an error. And again, we see an error message about the MessageBodyWriter not being found. But in this case, we correctly see that the type is application/json. So here we're sort of hitting a wall, where the Jersey implementation is telling us that it cannot turn this list of courses into a JSON output. It turns out that if you want Jersey to generate JSON responses, you will need to add an additional dependency. There are multiple ways to get Jersey to generate JSON, but we are going to introduce the artifact‑jersey‑media‑json‑jackson because we already use Jackson in our application, and this is sort of a bridge library that allows Jersey to use Jackson to serialize and deserialize JSON in endpoints. Again, this dependency is only required at runtime for the server, and we're not going to use any code directly from this dependency in our application. Let's restart the application again with this dependency in place. And by the way, this jersey‑media‑json‑jackson dependency transitively brings in Jackson itself, so we don't have to explicitly add that as a dependency. And now that the application has started, let's go back to the browser one final time. Now, after reloading, we can see that the server returns JSON. And for each course, we see the id, name, length in minutes, and the URL. And the only thing we had to do was to change the return type of our getCourses method and add the right dependency for Jersey to turn a list of courses into JSON. There's one last JAX‑RS mechanism that I want to show here. Our current application assumes all goes well and doesn't have any specific error handling in the endpoint implementation. Should an exception occur, it will just be turned into a generic HTTP 500 error, as we just saw. But it doesn't have to be this way. We could, for example, add a try catch block around our CourseRepository call and catch to the RepositoryException that may be thrown. Of course, we can log the error, but what if, rather than ignoring this exception, we want to turn it into, for example, an HTTP 404 code Not Found. You can argue about the semantics here, saying that if something goes wrong in the CourseRepository, it may not be a 404, but let's assume that we want a 404 status code to be returned to the caller in this scenario. We can achieve this by throwing the Not Found Exception that is provided by JAX‑RS. There's specific handling for this exception in the Jersey implementation that turns this exception into a 404 status code that will be returned to the caller.

Updating the Repository to Store Course Notes
As a last major addition to our course info system, we're going to add an endpoint to our course info server that allows people to add notes on a particular course. The idea is that we're going to expose an endpoint in the /courses, and then pointing to a particular course id, /notes, where the body of the POST request contains the notes. Through such a request, the notes will be added to the course with a particular ID. To make that possible, we need to extend our course info repository implementation with a method that can add notes to a particular course through a SQL update statement. And we also need to update our course domain class so that it can contain nodes. So we'll have to take care of these two points first, before we can start implementing the endpoints. I'm going to do this refactoring in a bottom up manner, starting at our course domain class. As the fifth component in the course records, I'm going to add notes as an optional string. It needs to be an optional because when we retrieve courses from the Pluralsight API and we're going to store them, there are no notes yet. These will be added later through the API. We can update our validation, calling the field method on the contents of the optional if it is present, but we immediately see that this is not a backward‑compatible change. An IntelliJ shows us that the addition of nodes brings five compile‑time problems to the code base. Let's take a look at them one by one. The first problem arises in the CourseStorageService of our CLI tool, where we are turning a PluralsightCourse into a course. Here we can just define the notes to be empty. So that's an easy fix. Then we also need to update the associated tests so that we expect empty notes there as well, and that leaves us with three remaining problems in the course‑info‑repository module. Two of those are in the test class that I haven't shown you yet, but that I ask you to write yourself. And if you did so, you will see similar errors. For the purpose of the first test, it doesn't really matter whether the optional is empty or not because the IllegalArgumentException is already triggered by the first null argument to course, but the second one is a bit more interesting because it relates to the new validation that we just added. Cheating a little bit before this refactoring, I provided an empty string for the second title parameter, causing this IllegalArgumentException, but that's not really what we want to test here. So I'm going to make the second parameter not empty. And the real case that we want to test here is where we pass an optional that is not empty, but it actually contains an empty string. Then we also want the IllegalArgumentException to be thrown. All right, so that's four errors down. Still one to go in the course‑info‑repository module. And that's an actual interesting one in our production code. Here we are instantiating a course based on the results in the ResultSet. Now, you may remember that our database table definition already included a notes column, but it was nullable. So until now, all of the courses that we inserted have a null notes fields in the database. Therefore, we can use the Optional.ofNullable method, passing in ResultSet.getString(5), which is the fifth column containing the notes, and this will either result in an empty optional if there's a null in the column, or it will result in a non‑empty optional containing the notes that are in the database. So at the moment, we would expect all of the courses that we have stored in the database to have an empty optional here. However, that's going to change because we're also going to make it possible in our CourseRepository implementation to add notes to an existing course. And again, let's do the refactoring in such a way that IntelliJ can guide us. We're going to the CourseRepository interface definition and adding method addNotes that takes an id that is the course id, and notes, representing the notes that should be added to that particular course. We can use the related problems that IntelliJ points out to find the interesting pieces of code that we need to update. And it turns out that there are two implementations of the CourseRepository interface in our code base. The first one is the InMemoryCourseRepository that we used for testing purposes. Since for now our tests don't rely on the addNotes functionality, we'll just put throw new UnsupportedOperationException here. And should that change in the future, then it's clear that something needs to be implemented here as well for the InMemoryCourseRepository. The more interesting implementation, of course, is our CourseJdbcRepository class. So let's use Alt+Enter again to introduce the addNotes method here as well. Before we're going to implement the addNotes method, I'm going to introduce a constant containing the SQL query to update a course with new notes. As you can see, we have two placeholders again, the first one for the notes themselves, the second one for the id of the course, which means that we're going to use the PreparedStatement API again. I'm going to copy the implementation of saveCourse, which is similar in structure. But in this case, we need to use the addNote constant for the PreparedStatement call. We need to set the right parameters for the placeholders, so the notes in the first position and the id in the second position. And we need to change the exception message to suit the implementation. And now we have a fully functioning addNotes implementation in our CourseJdbcRepository. We could also refactor this class a bit since we copy pasted some codes from saveCourse. So there's some overlap between the structure of these two methods that we can extract. It goes too far to do it here, but if you look at the final implementation of CourseJdbcRepository in the GitHub repository, you can see the approach I used to extract the common analysis between these two methods. And if you want, you can, of course, try this yourself first. We are now going to continue with the implementation of a post endpoint in our CourseResource class, because in the end, that's why we made all these changes to the course‑info‑repository module so that we would be able to use it in the endpoints to add notes to our courses.

Adding Notes through the REST API
In the CourseResource class, we're going to add a new method for adding notes to courses. We'll call it addNotes, and it takes two parameters, the id of the course that we want to add notes to, and the notes themselves. As we know from our previous endpoint implementation, we need to add some JAX‑RS annotations to turn this into an endpoint. We're going to use the @POST annotation, wince we want the users of this API to use HTTP POST to get to this endpoint. For this endpoint, we are going to provide a particular path using the @Path annotation. We configure it to /id/notes, where the id uses curry braces to indicate a placeholder syntax, which we can later bind to the string id parameter in the addNotes method below. The path we define in this annotation is relative to the path we provided at the class level. So the complete path to reach this endpoint will be /courses/id/notes. This endpoint will act the opposites from the endpoint that we already have, so it will not return any information, hence the void return type, but it will accept in notes as the body of the HTTP POST request, and by using the @Consumes annotation, we can indicate that we expect this body to be plaintext. We can then use the JAX‑RS @PathParam annotation, indicating that the id in the path that we configured as a placeholder should be bound to this parameter called id. So whatever value the caller puts in the id placeholder location will be put into the id string parameter that we have in the AddNotes method. The implementation is now quite straightforward. We can call addNotes on the CourseRepository, pass in the id of the course that we want to add the notes to, and pass in the notes that we also get as a parameter on our addNotes method here in the CourseResource class. And remember the notes parameter is filled with the body of the HTTP POST request that we're receiving here. Looking at the implementation of this method, there are literally more annotations than lines of code. And these annotations are all required to steer the Jersey implementation into the right direction. Such is life for many Java frameworks nowadays. Many of them are heavily annotation‑driven. And granted, it does lead to concise code, but sometimes it's hard to find out how to make the magic happen and to find the right annotations in the right combination. There's definitely much more to learn about building RESTful API S using JAX‑RS. But for this course, this will be all the ground that we cover around this topic. So let's try this new endpoint out. Unfortunately, we can't really use the browser like we did for the GET request, so we're going to use a command‑line tool called curl, which allows you to craft HTTP requests from the command line. It's available on Mac and Linux, and if you have a recent version of Windows 10 or later, that also comes with curl pre‑installed. If it's not available, you could install it yourself, or you can also use a tool like Postman to do HTTP calls. With the das‑x flag, we can configure the kind of HTTP method that we want to use, POST, in our case. Then we are going to configure a header Content‑Type indicating that the body of this request will be of type text/plain, which corresponds with our @Consumes annotation on the addNotes method. Then using ‑‑data, we can provide the body. Let's just provide "My course notes..." and some notes to add here. And finally, we need to provide the URL. Of course, it starts with http://localhost:8080, and then there's the common prefix of our API, /courses, followed by an id which points to my Java SE 17: The Big Picture course, but you could use any id of a course that's in the database here, and then /notes. So let's start a server, or restart it if it was still running for you, and we'll go back to the terminal again to execute the curl command. The command runs successfully, which means that notes should be added to the course in the database. We can verify this by going back to the browser again and reloading the overview of courses that are returned as JSON. And as you can see, something changed, but it's not exactly what we would expect. The note field is not serialized as we would expect. Rather than seeing null, if there are no notes, or the actual string if there are notes in the database, we see the internal details of the optional class, indicating whether the optional is empty or present. The good news is that for the Java SE 17: The Big Picture course, which we just used in our curl call, it does show that the notes are present, whereas for the others, the notes are not present. But that's not good enough. We really want to see the notes here. The problem that we're running into here is that Jackson, our JSON library, does not support serializing optionals the way we would expect out of the box. To fix this, we need to add the jackson‑datatype‑jdk8 artifact as dependency. Like many of the previous dependencies that we added, this one also only needs to be available at runtime for the server to use. And by introducing this dependency, Jackson can now handle optionals, but also streams, which is interesting because it allows us to improve our getCourses implementation a little bit as well. There, we can change the list return type into stream, and we can drop the final toList call. Let's start CourseServer again, and this time I'm getting a different dialog because I don't use the restart functionality. IntelliJ helpfully informs us that CourseServers is already running, and we need to decide whether we want to cancel this new run or to stop the old one and rerun the CourseServer class. And that is indeed what we want, so let's click Stop and Rerun so that we have CourseServer running with the new Jackson dependency. Going back to the browser, we can reload the overview, and now things look much better. All courses return null for notes, except one, and that's the course where we added "My course notes..." which we can see here. And that's it. We completed the REST API implementation for a course info system using JAX‑RS and Jersey.

Summary
Together, we built a REST API for our course info system. With an HTTP GET request, we return the stored courses as JSON, and through a POST request, we can now add notes to an existing course. Implementing the API was relatively straightforward due to our use of the JAX‑RS API. Even though JAX‑RS is part of the Jakarta EE enterprise Java specification, we could use it standalone through the Jersey implementation. In just a couple of lines of codes, we configured our resource class to be run on localhost. JAX‑RS is a heavily annotation‑driven API, where we instruct the implementation to behave in certain ways in a declarative manner. It's good to see this in action, since a large number of Java frameworks work this way using annotations. If you want to go deeper into creating REST APIs using JAX‑RS and Jersey, there's a Jersey 3 Fundamentals course on Pluralsight to help you. We are ready to move to the final phase of our project, making it production‑ready

Moving Towards Production
Unifying Application Logging
Functionally, we're done with the course info system. But that doesn't mean our work as developers is finished. There are still things we can do to make a project more robust and ready for production. In this final module, we'll look at a few of these things where we change some of our code to make it better suited for future use and also improve the structure of our Maven dependency management. As a last improvement point, we'll look at a way to ship the course info server as a single self‑contained .jar file. And finally, I will provide you with some ideas to develop the course info system further so you can practice your Java skills, and I will also provide some next steps to continue your learning journey as a Java developer. But first, let's make sure our application is logging in a unified manner. As you may remember, the log outputs of the course info server show two different logging formats. How come? Because we are using SLF4J as a single front end to our logging. And indeed, all of the code that we have written is using the SLF4J API, meaning that all of the log statements that we emit will be logged by the simple logging back ends that we introduce. However, we are also using external libraries, such as Jersey for our REST API. And unfortunately for us, Jersey internally uses the JDK logging API to do its internal logging. In practice, this means that at runtime there are two logging implementations in use. Our simple logging back ends that we use through the SLF4J API, and the JDK logging API. We can easily see this when we start the CourseServer class. The first log statement, which we emit ourselves from the main method using SLF4J, is formatted in a single line, whereas the subsequent log statements are all spread over two lines because these are logs using the JDK logging API, which is a different logging back end using different formatting. When you're running an application in production using two different logging formats, things can get confusing, especially when you want to start integrating with log management tools to do searching because many of these tools want the partial log lines and having a single format is required. So how can we fix this situation in our course info server? We can solve this by introducing a bridge library, which redirects JDK logging calls to SLF4J. That way, any logging done by libraries using JDK logging will now end up in the SLF4J logging back ends that we provide, which currently will be the simple logging back ends, but it can be any back ends that SLF4J supports. The JDK logging API will, of course, still be there, it's just not used anymore because the calls to JDK logging are intercepted and redirected to SLF4J. So we need to introduce this JUL, which stands for Java util logging, to SLF4J library. But as we'll see in the demo, that's not enough. We also need to add some code after introducing this bridge library to ensure all JDK logging is redirected to SLF4J. So in the next demo, we're going to add this library and write a little bit of code to ensure that we have unified logging in our course‑info‑server application. In order to add the dependency to the bridge library, we're going to the pom.xml file of course‑info‑server. Let's find the other SLF4J dependencies and add the JUL to SLF4J dependency there. We can reuse the slf4j.version property that is already defined. The dependency should have the default compile scope, as we need to initialize this bridge library ourselves. We are going to do this in our CourseServer class, which is the first class to be loaded and started from our application. Let's introduce a static initializer block in this class. A static initializer block will be executed once when the CourseServer class is loaded by the JVM. This is exactly what we need because this will happen very early on in the lifecycle of our application, and what we're going to do in this initializer block is to get the JDK logging LogManager and go reset on it. Then we are going to call install on SLF4JBridgeHandler, which comes from the bridge library that we just introduced as a Maven dependency. This bridge handler takes care of installing some hooks into the JDK logging API that were redirected to SLF4J. Since all of this code is executed very early before any of our other code is executed, all subsequent calls to the JDK logging API will now be intercepted by the bridge handler and redirected to SLF4J so that we have one unified logging approach in our application. Let's see what this looks like by starting CourseServer. You can now see that all log lines follow the same formats as the first log line that we emit ourselves using the SL4J API, which means that the installation of the bridge library has succeeded. In a real production application, you may want to switch out the simple logging back end for a full‑fledged implementation, like logback. And in that case, the SLF4J bridge setup that we have here will still work, so all log statements will then end up in this new logback implementation, where you can configure the log formats as you see fit, and it will apply to both the logging that is coming from our application and all the logging that is done through the JDK API.

Introducing External Application Configuration
We're now going to look how we can externalize configuration for a Java application. And with externalizing, I mean moving configuration data out of code. Why? Well, we don't want to hard‑code things into our Java code that might change between different deployment environments for our application, or things that should be controlled by the installer of the application rather than the developer of the application. There are several approaches we can use here, for example, using environment properties or command‑line arguments, as we've already used in our CLI tool. And both of these options can work with Java applications, but they're not that user‑friendly, especially if the amount of configuration grows. So in this demo, we're going to look at another option, that is, using configuration files that contain configuration properties for the application. To illustrate how Java properties files work, we're going to externalize one configuration item. We currently have the name of the database hard‑coded into our CourseServer class. That's a great piece of configuration data to externalize, since we might have different database names in different environments, or you might simply want to point to a different database without having to recompile the code. In order to externalize this configuration, we're going to introduce a new server.properties file in the resources folder of our Maven source layouts. Files that we put in the resources folder will be bundled into the resulting .jar file of the course‑info‑server submodule. The Java properties file formats is pretty straightforward. We provide a key, here course‑info.database, followed by an equal sign, and then the value that we want to give to this key. For now, we'll simply go with the value that was hard‑coded in the CourseServer class. Next up is actually loading the database file name from the properties file, rather than using the hard‑coded value that we currently have in our class. Let's start out by introducing a local variable, databaseFilename, and we'll defer the loading of this databaseFilename to a new method, loadDatabaseFilename. Before we implement these methods, let's also update our log statements to also log the databaseFilename that we're using when starting the application. And of course, update the call to openCourseRepository to use our loaded databaseFilename, rather than the hard‑coded one. But then, of course, we get to the interesting part, where we need to implement the load databaseFilename method. We want to load the databaseFilename from the server.properties file that we just introduced. Java has built‑in support for these properties file formats, so we don't have to do the low‑level parsing of key‑value pairs ourselves. Instead, we can use the Java util properties class, we can instantiate it and then call loads. There's an overload that takes a reader and there's an overload that takes an input stream, and we'll use the second one, but as you can see, there's also a load from XML option. So it is possible to also have a Java properties file in XML format, although in the wild I don't see this a lot, and people usually prefer the key is value formats. So let's go with the input stream overloads. But how do we actually get an input stream from the server.properties file that we put into the resources folder? As mentioned before, by putting it in the resources folder, it becomes part of the .jar file, which means that it's available on the class path for us to load. Since we're dealing with an input stream that also needs to be closed again, we're going to introduce the try with resources statement again, and then we're going to open the input stream by using CourseServer.class and calling getResourceAsStream, passing in /server.properties, which means that it will look in the root of the class path for a server.properties file. We also need to deal with the IOException that can be thrown by opening this resource as a stream, and we'll simply do that by throwing an IllegalStateException, which is a runtime exception. Now, that was all of the setup, but we still have not loaded our databaseFilename as a property. Fortunately, doing so is now rather easy. We can just call get .property on our properties object, passing in the key of the property that we want to load. So that's course‑info.database. And now our load databaseFilename method reached from the server.properties file. Let's prove that it works by starting CourseServer, and as you can see in the initial log line, we are loading from the courses.db file, which now comes from server.properties. If you want to practice some more with externalizing configuration, you can also try to extract a base URI constant that is now hard‑coded into this class into the properties file.

Using Maven's Dependency Management
We can improve our Maven multi‑module setup by extracting commonalities to the top‑level POM. Our goal is to avoid having the same information scattered across different POM files, which would otherwise make it harder to maintain them, and also to keep, for example, versions in sync across different POM files. To improve the setup we have, we'll use Maven properties, and we've seen those before, but also a feature which we haven't seen yet, which is Maven's dependency management section. We're going to start with our improvements in the pom.xml of course‑info‑cli. We are already using two version properties for SLF4J and for Jackson, which is great because that means inside this POM, we are not repeating ourselves. However, we are also using SLF4J and Jackson in the course‑info‑server module. There we currently do repeat these versions, and it's possible for them to get out of sync. The fix is pretty easy. We're going to lift the properties from this course‑info‑cli pom.xml and add them to the top‑level parent POM, which means that these properties are now available in the parent POM and in all the sub POMs. That means that we can now go into the course‑info‑server POM file and remove the slf4j.version property there, since we inherited from the parent POM already. With this set up, if we want to upgrade our SLF4J version, it means we only have to update the slf4j.version property in the parent POM, and all of the modules in our application will start using this new version. Also, since we now have a top‑level jackson.version property, we can start using that in the course‑info‑server pom.xml as well for the jackson‑datatype‑jdk8 artifact that we have in there. Good. That means that we now have a single place where we manage the properties for all of our modules. But we can even go a step further by using Maven's dependency management feature. This works as follows. In the top‑level POM, we can introduce a dependency management section, which looks similar, but is not quite the same as the dependency section that we have already seen in other POMs. Rather, we can nest a dependencies declaration inside of the dependency management elements. And you can view this section as being sort of a template for the dependencies that can be used in the submodules. So any dependencies that we declare inside of dependency management will not directly be treated as dependencies for these projects, but we can configure them here up front by defining the group id, artifact id, version, and scope, so that when we actually want to use them as dependency in a sub POM, we only have to declare the group id and the artifact id, and we can leave out the version and the scope, as that is managed through this dependency management section in the top‑level POM. This means that we will have a single place for shared dependencies across modules to define their version and our scope so that we can also upgrade the version in a single place or change the scope. Any changes made here will be automatically picked up in sub POMs, where we use the dependencies. Let's start applying this to our application so it becomes clearer what this means. First, I'm going to copy the SLF4J dependency declarations because these two dependencies are used in multiple modules. By adding them as dependencies in the dependency management section with a version and a runtime scope, in this case, for SLF4J simple, we can do the same for our JUnit dependency, which is also used and declared in multiple submodules. We now have a dependency management section that declares that if we're going to use slf4j‑api, or slf4j‑simple, or junit‑jupiter as artifacts in our downstream POMs, they will be fixed to the version that we configure here in the parent POM and to the scope which we define here as well, which is the default compile scope for slf4j‑api, the runtime scope for slf4j‑simple, and the test scope for JUnit. So in the course‑info‑cli POM, we can remove the version and the scope for these dependencies. Let's do this for JUnits slf4j‑simple and slf4j‑api. The fact that JUnit should be a test code dependency and fixed to a certain version is now configured in the parent POM. And if we want to change or update that, we can do this in a single place and it will be picked up by all submodules that actually declare JUnit as a dependency in their dependency section. Now, I'm also going to copy the two dependency declarations for jackson‑databind and jackson‑annotations. And you may be wondering why because technically they are only declared in the course‑info‑cli POM. However, as you may remember, in our course‑info‑server POM, we introduced a jersey‑media‑json‑jackson dependency, which in turn transitively brings in jackson‑databind and jackson‑annotations. By lifting these dependencies to the parent dependency management section, we are actually telling Maven that whenever a dependency is pulled in under jackson‑databind, whether it's explicitly in our POM file here in course‑info‑cli or whether it is transitively as in course‑info‑server, they all should converge on the same version that we define. Otherwise, the transitive dependency from jersey‑media‑json‑jackson that is pulled in could be a different version of Jackson than the one that we declare. So we bring the Jackson dependencies to the top‑level dependency management section. By doing so, we have now ensured that not only the versions that we use directly from our POMs are fixed to the version that we define in the dependency management section, but also any of these two Jackson artifacts that are pulled in transitively through another dependency will now conform to the version we declare in the dependency management section. We can now wrap up these improvements by removing any redundant information that is still there in the sub‑POMs. So that means that we can remove the version from jackson‑databind and jackson‑annotations, but it also means that we can go into the pom.xml of course‑info‑repository and remove the version and the scope from the JUnit dependency, as we have already declared centrally in the dependency management section of the parent POM. And the same goes for the course‑info‑server POM, where we can remove the slf4j‑api version and slf4j‑simple version. Note that we cannot remove the version of JUL to SL4J, since this artifact is only used in course‑info‑server, and hence, it has not been added to our dependency management section. Fortunately, we still refer to the centrally managed slf4j.version property here, so we can still upgrade all of our SLF4J artifacts in logstep by upgrading the slf4j.version property. Some Java projects make the choice to move all dependency declarations to a dependency management section, even if they're only used in a single sub‑POM, because, well, in the future that might change, and the dependency might also be used in another sub‑POM. Setting up your POMs that way is also a valid approach. Since we've changed quite a lot in our POM files, let's open the terminal and run a Maven build to see whether it still runs without any problems. And luckily, that's the case, and we are left with a POM setup that has less duplication and is easier to maintain.

Creating a Self-contained Runnable JAR File
This brings us to our final challenge. How can we ship our application to end users or install it on a server? Technically, we can already do so, since the Maven build produces a .jar file for all modules. So, given a machine that has the right Java version installed, we could copy this .jar file and run it with Java and this .jar and then the name of the .jar file, course‑info‑server, in our case. However, that's only part of the story because this .jar file only contains our codes. But we also use many libraries from our codes, and these have to be provided on the class path to the JVM as well. So not only do we need to ship the application with all of its dependencies, we must also ensure that it is started using the right class path, and that can be quite a challenge. During development, Maven handled all these dependency and class path issues for us, but we can't rely on Maven for actually running our application in production. Now, you could, of course, set up the whole application with its dependencies and Java in a Docker container and ship that, and that's a perfectly valid approach. But in this demo, I want to show that we can also create a single, runnable .jar file for our course‑info‑server application as an alternative way of distributing this application. Once we have the single runnable .jar file, we only need a machine that has the right Java version, and we can easily start it using java ‑jar, and then the name of the single runnable .jar file. So let's see how we can make that happen. I've opened the course‑info‑server pom.xml file because we want to run the course‑info‑server as a standalone jar. Of course, later, you can do something similar in the course‑info‑cli POM if you want to. I'm introducing the build and plugins elements so that we can configure a new build plugin for this module. The plugin that we're going to use is called the maven‑shade‑plugin, and the way that it works is that it collects all class files that have been compiled for our application, but also all class files from our dependencies. It then takes all of these class files and puts them together in a single .jar file. This usually means it becomes a very big .jar file because it contains all class files that we need to run our application. And there are also some potential issues with the maven‑shade‑plugin approach of just combining all resources from different .jar files because there might be conflicts and things might be overwritten, and we'll see one instance of such an issue shortly. However, in practice, this plugin seems to work nicely for most scenarios. This plugin is tied to the default Maven package phase. So when we invoke Maven clean verify later, this plugin will be invoked automatically as part of the build for the course‑info‑server module. But before we do so, we still need to add some configuration. The maven‑shade‑plugin supports a concept called transformers, and the first transformer that we're going to add ensures that the manifest of the generated .jar file will point to our CourseServer class as the main class to be started when running this .jar. The second transformer that we're going to add is called the ServicesResourceTransformer. And this transformer has everything to do with the conflicts that may arise between different .jar files when you copy all of the resources into a single .jar file. Going into the details of this issue goes far beyond this course, but several .jar files contain similarly‑named configuration files, and this transformer makes sure that they are merged rather than overwritten. With these transformers in place, we're going to open the terminal and run mvn clean verify. This rebuilds our whole projects and also invokes the maven‑shade‑plugin as part of the packaging phase. Looking at the target folder, we now see two .jar files. One is called original‑course‑info‑server and its renamed original .jar file that only contains the course‑info‑server classes. We also see a .jar file called course‑info‑server, and this is the .jar file that now contains all of our dependencies and our own codes. And hence, this will be the .jar file that we can easily distribute and run everywhere. To prove that this works, let's try starting this .jar file. So we're going to start our course‑info‑server application, but this time not through IntelliJ, but instead we're going to start it from the command line using the JVM, the Java commands directly, and pointing it to the single runnable .jar file that we just created. We see the familiar logging of our CourseServer application. It says the HTTP server is started successfully. If you try this yourself, first ensure that the application is not running inside of IntelliJ anymore. Otherwise, you will here see an exception telling you that it cannot bind to port 8080 because that's already in use. Now, to prove that this is still the same server application as we were running from IntelliJ, but now on the command line, let's go to the browser and load localhost:8080/courses. And there we still see the overview of all of the courses that are in the database. So everything is working as expected. You can now take this single runnable .jar file and ship it to any machine that has the JDK installed, and you can start the server application with just a simple Java desk .jar command without having to set up the whole class path yourself.

Next Steps for the Course Info Project
You did a great job! We now have a Java 17 codebase that uses industry standard tools and libraries. But of course, there's much more that you can do to build out your Java knowledge based on this project. One way is to identify some functional enhancements to the course info system and implement these. For example, try to find another source for new courses to add into the system and write code to retrieve and process those courses, like we did for the Pluralsight API in the CLI tool. You can either extend the current CLI implementation or add a new one. Alternatively, you can extend the REST API that we now have, for example, by adding functionality to delete a course. This entails adding at least a new method on our CourseResource class that corresponds to an HTTP DLETE request for a given course ID, and updating the repository implementation to support deleting courses. And there are many more additions that we can think of, such as an update endpoint for courses, or creating a course through the REST API, all of these will require you to dive into both the repository and the server implementations. You can also look at more technical enhancements for this project. One idea is to replace the H2 database with something else. H2 is not really meant for high traffic and concurrent usage, so if you want to bring this project to the next level, introducing a real database server would be a good idea. Postgres is a great choice, and there's a JDBC driver for Postgres available. Making this change requires tweaking the repository implementation to connect to a Postgres server using the Postgres JDBC driver. If you make this change, you will also have to figure out a way to create the right database tables, since you can't use this handy H2 in a script functionality. There's probably a Postgres equivalent, but you can also look into production‑grade tooling for managing SQL database schemas that exist in the Java ecosystem. Because ultimately, creating a database schema is not a one‑off action, but usually is an ongoing concern when requirements change and your database needs to adapt. Integrating tools like Flyway or Liquidbase into your application can make versioning and managing your database schema much easier. As a final suggestion, you could also introduce a so‑called client library as convenience for other Java developers that want to call the CourseServer REST API. You can do this by introducing a new Maven module in the project that will result in a new library .jar that other applications can use to call the course info system using Java. Internally. this client library would call our Course Info REST API over HTTP, but it would provide a convenient Java interface to the outside world. You can use the Java HttpClient that we learned about to implement such a client library. As you can see, there are many possibilities to keep working on this codebase while learning new and useful skills.

Next Steps for You
Wow! You've been on quite a journey. Looking back with your coworker, you're quite happy with how the first version of the course info system turned out, and you've got plenty of ideas to extend it further now. But how to continue learning after this project? Hopefully, you've seen some new tools, libraries, APIs, and Java language features that you want to learn more about. Let me provide some pointers on how you might continue learning. Some of the things that you learned in this course are more general to Java developments, and some are more specific to the libraries we chose. But the overall approach and tooling we've used should give you enough backgrounds to build your own Java applications. So now it's time to practice your skills. And practicing means logging off of Pluralsight for a bit and firing up your IDE to write some code. This could be a new application, or you could extend the course‑info projects with some of the ideas that we already saw. But in the end, the more code you write, the better you'll become. If you're looking for some next steps to continue learning on Pluralsight, I have some recommendations as well. In this course, we did not use a Java framework on purpose. But that doesn't mean you shouldn't look into Java frameworks, of course. In fact, most applications you'll encounter will make use of one of the big frameworks in the Java ecosystem. So as a follow‑up to this course, it makes sense to pick a framework and start diving deeper into how it works. Which framework can depend on what's used in your company, or it can be based on your own interests, of course. Spring Framework is definitely one of the most popular Java frameworks. So starting on one of the Spring Framework learning paths at Pluralsight is a great way to get into Spring. Alternatively, you can look at enterprise Java with the Jakarta EE Web Profile: The Big Picture course. This will give you an overview of what Jakarta EE can do as an enterprise Java application framework. Besides looking at Java frameworks, the Java language itself has also evolved quite a bit, deepening your Java language expertise based off no matter which framework you will end up using. I can highly recommend watching courses on the Java SE learning path at Pluralsight to develop your core Java skills. Thank you so much for taking the time to finish this course. It was my pleasure to introduce you to the world of building Java SE applications. If you like, feel free to follow me on Twitter through @Sander_Mak, or on LinkedIn. In both places, I regularly post interesting Java and general software development‑related content. Did you know you can follow authors on Pluralsight as well? If you go to my author page through the link shown here and click the Follow button, you will get updates whenever I release a new course. You can also find an overview of all my other Pluralsight courses on this author page. For now, I want to wish you good luck with your next steps into Java 17, and I hope to see you back in one of my other courses.

</details>



<details><summary>

###### Credit(s)/Other(s)/Reference(s)/Source(s)/Thank(s)  </summary>

Course done between  
08/09/2024 to 08/14/2024

</summary>

</details>